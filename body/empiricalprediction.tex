% !Mode:: "TeX:UTF-8" 

\BiChapter{克隆代码一致性维护需求预测实证研究}
{An Empirical Study on Clone Consistency-Requirement Prediction}


\BiSection{引言}
{Introduction}

%由于日益增长的软件开发的需求，开发人员在软件开发过程中通过复制粘贴既有代码，向系统中引入了大量克隆代码。
克隆代码在随着软件演化的过程中，可能会被程序开发人员修改而引发克隆代码的一致性问题。为解决此问题，本文在第三章和第四章分别在克隆代码创建时和变化时，对克隆代码的一致性维护需求进行了预测。但是，上述方法中仅考虑了贝叶斯网络方法，能否将其它机器学习方法（如支持向量机、决策树等）应用到此克隆需求预测中是一个值得研究的问题。此外，上述预测也没有和软件开发过程相结合，在开发过程中预测克隆一致性需求，可以切实的帮助程序开发人员避免克隆代码导致的额外维护代价和克隆一致性缺陷，从而帮助提高软件质量和可维护性。

鉴于此，在第三章和第四章研究的基础上，本章统一了克隆代码创建时和变化时的克隆代码一致性变化和维护需求定义，并使用五种不同的机器学习方法进行克隆一致性维护需求预测实证研究，并与软件开发过程相结合预测克隆一致性需求。首先通过构建软件系统的克隆家系来收集系统中所有的克隆实例（克隆创建实例和克隆变化实例），并提取不同的属性值表示不同的克隆实例。然后，使用五种不同的机器学习方法，分别在克隆创建时和变化时预测克隆代码的一致性维护需求。最后，结合软件开发过程，设计并实现了克隆代码一致性维护需求预测插件（CCRP），并可以嵌入到集成开发环境eclipse中预测克隆代码一致性需求。本章在四个开源软件系统上进行了实证研究，实验结果表明本文所提取的属性值可以适用于不同的机器学习方法上，且支持向量机方法更适合于克隆代码的一致性维护需求预测中。本章基于eclipse所实现的插件，可以帮助开发人员在软件开发过程中预测克隆代码的一致性，降低克隆代码导致的额外的维护代价，避免克隆变化导致的一致性缺陷，从而提高软件质量和可维护性。
%支持向量机方法具有最好的实验效果。



\BiSection{克隆代码一致性维护需求}
{Clone Consistency-Requirement}

\BiSubsection{研究问题}
{Research Problem}

在软件开发过程中，通过复制粘贴操作复用既有代码已经成为一种常见的软件开发手段，但是也会向软件系统中引入大量的克隆代码。这些新创建的克隆代码以及系统已经存在的克隆代码并不是静止不变的，会随着软件系统演化。在演化过程中，克隆片段片段可能会被软件开发员修改而发生变化，并可能进一步引发克隆组的一致性变化。克隆代码的一致性变化问题会影响软件质量和可维护性，原因在于：程序开发人员需要对发生变化的克隆进行一致性维护，会导致额外的一致性维护代价。而遗忘克隆的一致性变化，更会会导致克隆不一致缺陷，从而进一步增加软件的维护代价。

为了解决此问题，本文的第三章和第四章分别在克隆代码创建时和变化时，基于贝叶斯网络对克隆代码的一致性维护需求进行了预测，并取得了不错的预测效果。上述方法中仅仅使用了贝叶斯网络作为预测模型，但是在机器学习领域中仍然存在着其它的机器学习方法。因此，这启发了本章对克隆一致性预测的深入研究。首先，能否将克隆代码的一致性维护需求预测应用到其它的机器学习方法中。然后，在这些机器学习方法中，能否为开发人员确定一种通用的机器学习方法，可以同时应用于克隆创建时和克隆变化时的一致性需求预测中。 最后，对于两个不同的预测时刻（创建时和变化时），如何在软件开发过程帮助程序开发人员选择合适的预测时间，并达到最好的预测效果。更为重要的是，上述克隆一致性维护预测研究尚未与软件开发过程相结合，不能帮助程序开发人员在开发时预测克隆代码的一致性。

为了更好地帮助软件开发人员维护克隆代码，本章将结合其它机器学习方法和软件开发过程，对克隆代码进行一致性维护需求预测的实证研究。具体地，本章地研究问题如下：

\textbf{Research Problem： 克隆代码的一致性维护需求预测是否可以应用于其它的机器学习方法中，软件开发人员应如何结合软件开发过程中执行克隆一致性需求预测？}\\
%{\em {\bf Research Problem:} Whether this clone consistency prediction task can be applied by other machine learning methods, and how should the developer determine perform such prediction in practice?}

为了解决本章的研究问题，将使用五种不同机器学习方法来预测克隆代码的一致性维护需求，并且分别在克隆代码创建时和克隆代码变化时进行预测。同时，在预测克隆一致性的过程中充分考虑并结合软件开发过程，比较和讨论两种不同预测的时间，从而帮助开发人员实际开发环境中执行克隆代码一致性预测，具体地，本文章研究问题可以细分为以下三个子问题，如下所示：

{\bf RQ1：}
%子问题1: 
在预测克隆代码创建时的一致性维护需求时，哪些机器学习方法可以用于该预测中，且所提取得度量值能否应用于其他的机器学习方法中，不同的机器学习方法预测效果是否一致，哪一种机器学习的方法能够取得最好的结果？
%%{\bf RQ1:} At clone creating time, which machine learning methods can be employed for clone consistency-requirement prediction?}\\
%在这个问题上，我们将会按照Wang等人的预测。与代码和上下文的属性集的变体。
%在这个子问题中，本章将第三章中的方法应用于其它的机器学习方法中，

{\bf RQ2：}
%子问题2: 
在预测克隆代码变化时的一致性维护需求时，哪些机器学习方法可以用于该预测中，且所提取得度量值能否应用于其他的机器学习方法中，不同的机器学习方法预测效果是否一致，哪一种机器学习的方法能够取得最好的结果？
%{\bf RQ2:} At clone changing time, which machine learning methods can be employed for clone consistency-requirement prediction?\\
%在这个问题上，我们将会按照Wang等人的预测。与代码和上下文的属性集的变体。
%在这个子问题中，本章将第第四章的方法应用于其它的机器学习方法中，

{\bf RQ3：}
%子问题 3: 
在实际开发过程中，程序开发人员应该如何结合软件开发过程选择合适的机器学习模型和预测时间，并对克隆代码进行一致性维护需求进行预测，从而都够达到最佳的预测效果？
%{\bf RQ3:} Which technique of machine learning should they employ as their preference? And, how the developers perform these clone predictions to achieve the preferably effectiveness in practice? 
%将对比两者并且，开发一个产假

鉴于此，本章基于不同的机器学习方法对克隆代码的一致性维护需求预测进行了一个实证研究，同时在克隆代码创建时和变化时预测克隆代码的一致性，并结合软件开发过程帮助程序开发人员选择合适和机器学习模型和预测时间已达到最佳的预测效果。首先，统一了克隆代码创建时和变化时的一致性变化及其一致性维护需求定义，可以在一个框架下预测克隆代码的一致性维护需求。然后，充分考虑了机器学习领域中五种不同的机器学习方法，并将其应用到克隆代码的一致性维护需求中。最后，本章结合软件开发过程，将克隆一致性维护预测方法嵌入到软件开发环境（eclipse）中，帮助程序开发人员实现边开发、边预测、边维护克隆代码，从而可以避免克隆一致性缺陷，并降低克隆代码的一致性维护代价。
%因此，本章方法可可以提高系统的可维护性和软件质量。
%\footnote{eclipse插件开发环境。}

\BiSubsection{克隆一致性维护需求定义}
{The Definitions for Clone Consistency-Requirement}

在克隆代码的整个演化周期中，克隆片段可能会被开发人员修改，从而导致克隆代码的一致性变化。在本文的第三章和第四章分别提供了两种不同形式的克隆代码一致性变化定义，从而适应于不同时间的克隆一致性维护需求预测中。本章将统一第三章和第四章的定义，以应用于本章地实证研究中。具体来说，克隆代码的一致性变化如下：\\

\begin{definition}
[一致性变化（Consistent Change）]  
\label{def-change}
给定两个克隆代码片段 $CF_1$和 $CF_2$，且它们被分别地修改为$CF'_1$和$CF'_2$。 如果对于一个非常小的阈值$\tau$，如果克隆代码$CF_1$和$CF_2$的变化满足以下条件，称此变化为一致性变化（Consistent Change） , 
  \[
  \begin{array}[t]{crl}
    \mathit{textSim}(CF_i, CF'_i) < 1 & \forall i \in \{1,2\} &(1) \\
    \multicolumn{2}{c}{| ~\mathit{textSim}(CF_1,CF'_1)  ~-~ \mathit{textSim}(CF_2,CF'_2) ~| ~< ~ \tau}  & (2)
  \end{array}
  \]
更具体地，如果克隆变化仅满足条件1，将其称为Type-1一致性变化（{\em Type-1 Consistent Change}）；如果克隆变化同时满足条件1和条件2，将其称为Type-1一致性变化（{\em Type-2 Consistent Change}）。
\end{definition}

%\begin{definition}[{\bf Consistent Change}]  
%\label{}
%Given that two clone fragments $CF_1$, $CF_2$ are modified to $CF'_1$ and $CF'_2$ respectively. 
%We say this modification on $CF_1$ and $CF_2$ is a {\em\bf consistent change\/} if for some very small threshold $\tau$, 
%  \[
%  \begin{array}[t]{crl}
%    \mathit{textSim}(CF_i, CF'_i) < 1 & \forall i \in \{1,2\} &(1) \\
%    \multicolumn{2}{c}{| ~\mathit{textSim}(CF_1,CF'_1)  ~-~ \mathit{textSim}(CF_2,CF'_2) ~| ~< ~ \tau}  & (2)
 % \end{array}
 % \]
%More specifically, if they only satisfy condition 1, we call this as {\bf \em type-1 consistent change}, and if both conditions 1 and 2 are satisfied, we term it {\bf \em type-2 consistent change}.
%\end{definition}

定义中克隆代码$ CF_1 $和$ CF_2 $的变化情况由相似性度量$ \mathit {textSim} $进行定义，$textSim$与第三章和第四章计算方式相同。定义中的两个约束条件共同定义了克隆代码的一致性变化，约束条件$1$确保了克隆代码片段同时被修改，约束条件$2$克隆代码片段发生了一致性的变化，由变化阈值$\tau$指定。

其中，Type-1一致性变化又可以称为克隆创建时一致性变化，Type-2一致性变化又称为克隆变化时的一致性变化。这两种不同的一致性变化，将分别应用于两种不同时间的克隆一致性预测中。在克隆代码创建时，目标是避免新创建的克隆代码在其未来演化过程中的一致性变化，及其所导致额外的维护代价。所以，只要两个克隆片段同时变化，即认为会导致额外维护代价。因此，在克隆代码创建时使用使用Type-1一致性变化进行预测。在克隆代码变化时，目的是避免克隆变化可能导致的未来演化中的一致性变化，及其因此所引发的克隆一致性缺陷。所以， 不仅要求两个克隆代码片段同时变化，还需要发生相似的变化，否则将会引入克隆一致性缺陷，因此，在克隆代码变化时使用使用Type-2一致性变化进行预测。

在克隆演化过程中，克隆片段是以克隆组的形式出现在软件系统中。克隆代码的变化情况必然会导致克隆组的变化，而克隆组的变化使用克隆演化模式进行描述，即一致性变化模式。本文给出演化过程中克隆组的一致性变化模式定义，如下所示：\\


\begin{definition}
[一致性变化模式（ Consistent Change Pattern）] 
\label{def-pattern}
在软件版本 $j+1$中存在一个克隆组$CG'$ ，假设克隆组内至少存在两个克隆代码片段$CF'_1$ 和 $CF'_2$可以与映射到上一版本$j$的克隆组$CG$中，且 $CG$中与之对应的克隆代码片段的 $(CF_1,CF_2)$被修改为$(CF'_1,CF'_2)$。如果克隆片段之间的变化（ $(CF_1,CF_2)$变化至$(CF'_1,CF'_2)$满足克隆片段的“一致性变化（Consistent Change）”，则称克隆组$CG'$具有一致性变化模式（Consistent Change Pattern）。
\end{definition}

%\begin{definition}[{\bf Consistent Change Pattern}] 
%\label{}
%{\em
%A clone group $CG'$ in software version $j+1$ possesses {\em\bf type-1 or 2 consistent change pattern} if there exists a pair of clones $CF'_1,$ and $CF'_2$  in $CG'$ which are mappable to a pair of clones $CF_1$ and $CF_2$ in a clone group $CG$ in version $j$ such that modification of code pairs from $(CF_1,CF_2)$ to $(CF'_1,CF'_2)$ is a type-1 or 2 consistent change. 
%} 
%\end{definition}

其中“一致性变化”为Type-1或Type-2一致性变化，相应的克隆组变化模式则为Type-1和Type-2一致性变化模式。在相邻的两个软件版本中，克隆组一致性变化模式可以描述克隆演化中由于克隆片段变化所引发的克隆组的变化情况。

回顾本章地研究内容是要在两种不同的时刻预测克隆代码的一致性维护需求，结合第三章和第四章的克隆实例的定义，这里将统克隆创建实例和克隆变化实例为克隆代码实例，如下所示：\\

\begin{definition}
[克隆实例（ Clone Instance）] 
\label{def-instance}
克隆创建实例：软件版本 $j$中的一个克隆组$CG$是克隆创建实例，如果该克隆组$CG$是其克隆家系$CGE$的根节点。
克隆变化实例：
软件版本 $j$中的一个克隆组$CG$是克隆变化实例，如果克隆组$CG$中至少两个克隆片段发生变化且版本$j+1$ 中至少存在一个克隆组$CG'$与之对应（在同一克隆家系$CGE$中）。 
克隆实例： 将克隆创建实例和克隆变化实例统称为克隆实例。
\end{definition}
%In the above definitions, we identify a $CG$ created by a creating operation (copy and paste) as a new $CGE$ root that begins its evolution. 

%\begin{definition}[{\bf Clone Instance}] 
%\label{}
%{\bf Clone Creating Instance:}
%{\em 
%A clone group $CG$ in version $j$ is {\bf clone creating instance} if $CG$ is a root node in the clone genealogy ($CGE$). 
%}
%~\\
%{\bf Clone Changing Instance:}
%{\em A clone group $CG$ in version $j$ is a {\bf clone changing instance} if at least one clone group $CG'$ in version $j+1$ which is connected to $CG$ in the clone genealogy was modified. 
%}
%~\\
%{\bf Clone Instance:}
%{\em We call clone creating and changing instance as {\bf clone instance}.
%}
%\end{definition}


克隆实例在演化过程中可能会引发的克隆一致性变化，如果不能确保克隆的一致性，将会导致导致额外的维护代价和一致性缺陷。具体来说，对于克隆创建实例，本文认为Type-1一致性变化及其演化模式在克隆演化过程中可能会导致额外的克隆维护代价。对于克隆变化实例，本文认为Type-2一致性变化及其演化模式在克隆演化过程可能会导致克隆一致性缺陷。因此，本章尝试在不同的时间预测克隆实例的一致性维护需求，以避免额外的克隆维护代价和一致性缺陷。本章结合第三章和第四章的克隆代码一致性维护需求的定义，将克隆创建时和变化时的一致性维护需求统一为克隆一致性维护需求定义，如下所示：\\

\begin{definition}
[克隆一致性维护需求（Clone Consistency-Requirement）] 
 \label{def-requirement}
给定版本 $j$中一个克隆实例，$CG$满足克隆一致性维护需求（Consistency-Requirement），如果在版本$k$中存在一个克隆实例 $CG'$（$k>j$）满足以下条件： (1) 在$CG'$中至少存在两个克隆片段在其克隆家系$CGE$中可以映射到克隆实例 $CG$中， (2) $CG'$ 具有“一致性变化模式”（Consistent Change Pattern）。反之，假如克隆实例$CG$ 不满足克隆一致性维护需求条件，称该克隆实例不需要一致性维护（consistency-requirement free，或者consistency-free）。
\end{definition}

%\begin{definition}[{\bf Clone Consistency-Requirement}] 
 %\label{}
%{\em
%A clone instance $CG$ in software version $j$ satisfies {\bf consistency-requirement\/} condition if there is a clone group $CG'$ in software version $k$, with $k>j$, such that (1) there is at least a pair of clones in $CG'$ that is mappable in clone genealogy to a pair of clones in $CG$, and (2) $CG'$ possesses ``consistent change pattern''. When $CG$ does not satisfy consistency-requirement, we say that it is {\bf consistency-requirement free\/}, or simply {\em consistency-free\/} or {\em free} for short. %\\
%We employed the type-1 consistent change pattern for clone creating instance, and type-2 for changing instance.c
%}
%\end{definition}

其中，“一致性变化模式”为Type-1或Type-2一致性变化模式，相应的克隆一致性需求为Type-1和Type-2一致性维护需求。其中，Type-1克隆一致性维护需求可以用于预测克隆创建实例，Type-1克隆一致性维护需求可以用于预测克隆变化实例。

最终，克隆一致性维护需求预测任务可以转化为以下问题：
%{\bf Prediction Task:}
 给定一个克隆实例，克隆创建实例或者克隆变化实例，判断该克隆实例是否满足克隆一致性维护需求。
 
 更进一步，本文将克隆代码一致性维护需求预测问题转换成为一个分类问题，因而可以使用机器学习中的方法来解决此问题。在本文第三章和第四章的研究中，仅仅考虑了贝叶斯网络方法，为了更深入研究克隆代码的一致性预测问题，本文将会使用五种不同的机器学习方法在预测克隆实例的一致性维护需求。将在后文中详细介绍。


\BiSection{基于机器学习的克隆代码一致性需求预测框架}
{The Framework for Clone Consistency-Requirement base on Machine Learning}

为解决本章所提出的克隆一致性需求维护预测问题，本文首先给出了一个方法框架。基于机器学习的克隆代码一致性需求预测框架如图~\ref{framework5}~所示。方法可以划分为三个阶段，克隆实例收集阶段、克隆实例表示阶段和一致性维护需求预测阶段。收集阶段旨在收集系统中全部的克隆实例（包括创建实例和变化实例），可将其用于使用机器学习方法中来训练预测模型。由于实际的克隆实例无法直接应用于机器学习方法中，因此在表示步骤中将提取不同的属性值表示克隆实例，所提取的属性值将包含克隆实例的有意义的信息。接下来，在预测步骤，使用属性化的克隆实例构建和训练机器学习模型，并使用其预测克隆实例的克隆一致性维护需求。


\begin{figure}[htbp]
\centering
\includegraphics[width = 0.9\textwidth]{framework5.pdf}
\bicaption[framework5]{}{克隆代码一致性维护需求预测实证研究框架}
{Fig.$\!$}{The framework for empirical study on clone consistency prediction }
\vspace{-1em}
\end{figure}

具体来说，在收集阶段中，通过构建系统的克隆家系从软件中收集所有的克隆实例。使用NiCad来检测软件版本中的所有克隆，并通过在相邻版本的克隆组之间进行映射来构建克隆家系，用于识别克隆实例。在表示阶段中，通过提取属性值表示克隆创建和变化实例，提取代码属性和上下文属性表示克隆创建实例，提取代码属性、上下文属性和历史属性表示克隆变化实例。在预测阶段中，使用收集到的克隆创建实例训练贝叶斯网络，并在克隆创建时预测克隆一致性维护需求。在使用已构建好的模型进行预测时，可将该模型嵌入到软件开发环境中。软件开发环境需要实时监测克隆创建实例和变化实例并提取克隆实例的度量值。最后使用模型预测其一致性维护需求，根据预测结果提醒程序开发人员采取进一步的操作。

克隆实例有两种不同的预测结果，即满足一致性维护需求和不满足维护需求。
对于满足一致性维护需求实例来说，其在将来的演化中可能会引发一致性变化，程序开发人员需要采取相应的操作。例如，拒绝克隆创建实例或者检查克隆变化实例一致性。对于不满足一致性维护需求实例来说，其在将来的演化中不会引发一致性变化，程序开发人员需要采取相应的操作，如接受克隆创建实例。

本章使用多个不同的机器学习模型预测克隆实例的一致性。所提取的克隆实例的属性即为机器学习模型中的输入特征，用于构建不同机器模型的结构。所收集到的克隆变化实例可作为机器学习的训练集，用于训练机器学习模型的相关参数，细节可参考本文后续章节。
本章使用和比较五种不同的机器学习方法，以帮助开发人员选择最佳的预测手段。


\BiSection{克隆实例收集和表示}
{Collecting and Representing Clone Instance}

收集和表示克隆实例可以生成克隆一致性预测的训练集，为将克隆实例应用于机器学习中，提取不同的属性值表示克隆实例，从而可以训练机器学习模型。

\BiSubsection{克隆实例收集}
{Collecting Clone Instances}

收集克隆实例的目的在于生成克隆一致性预测的训练集，并将其用于训练机器学习模型。通过构建系统的克隆家系并识别其中的克隆演化模式，可以从软件中收集所有的克隆实例。首先使用NiCad来检测软件版本中的所有克隆，然后通过在相邻版本的克隆组之间进行映射来构建克隆家系，最后识别Type-1和Type-1克隆一致性演化模式识别系统中的克隆创建和变化实例。

根据定义~\ref{def-instance}~，克隆家系$CGE$中的初始节点即是克隆创建实例，发生变化的克隆组是变化实例，因此因此通过构建克隆家系可以收集克隆创建和变化实例。

（1）构建克隆家系。首先，下载系统所有版本的源代码，并使用NiCad的默认配置检测检测每一版本的中Type1-3的克隆代码。然后，通过映射所有相邻版本的克隆代码，构建系统中全部克隆家系。为完成版本间的映射，为每个克隆片段生成一个克隆区域描述符 $CRD$\cite{duala2010clone}，使用基于$CRD$的克隆映射算法映射两个连续版本之间的所有克隆片段和克隆组\cite{ci2013new}\cite{ci2013newD}。根据克隆映射结果，构建系统的克隆家系。

（2）识别克隆演化模式和收集克隆实例。首先，识别克隆家系中的克隆演化模式，尤其是克隆一致性变化模式。构建克隆家系后，通过对比相邻版本的克隆代码，可以识别克隆家系的克隆演化模式（参考定义~\ref{def-evolutionpattern}~和\ref{def-pattern}~）。所识别的克隆演化模式有三个作用：（a）克隆演化模式可以帮助收集克隆变化实例。根据定义~\ref{def-evolutionpattern}~可以识别系统中发生一致性变化的克隆代码和克隆组，从而确定克隆家系中的克隆变化实例。（b）可以用于表示克隆变化实例，本文使用克隆演化模式作为表示克隆变化实例的部分演化属性。因此，克隆演化模式可以用于克隆变化实例表示中。（c）克隆演化模式可以帮助确认克隆一致性维护需求。根据定义~\ref{def-requirement}~，一致性维护需求，可以通过遍历克隆家系$CGE$是否发生了一致性变化模式进行确定。

然后，收集克隆实例。根据定义~\ref{def-instance}~通过遍历克隆家系的根节点，可收集系统中所有的克隆创建实例。在收集克隆变化实例后，还需确认该实例中的被复制和被粘贴代码（参见本文第三章收集克隆创建实例小节~\ref{lab-checkcopied}~）。根据定义~\ref{def-instance}通过识别克隆家系中的变化克隆组，便可以收集系统中的克隆变化实例。

（3）标识克隆变化实例的一致性维护需求。在收集所有的克隆实例后，还需确认相关实例的一致性维护需求。根据定义~\ref{def-requirement}~，通过遍历克隆实例所在的克隆家系$CGE$的演化情况确定其一致性维护需求。如果克隆实例在其演化过程中发生了一致性变化模式（~\ref{def-pattern}~），则该实例满足一致性维护需求，否则不满足维护需求。

\BiSubsection{克隆实例表示}
{Representing Clone Instance}

本章使用机器学习方法预测克隆代码的一致性维护需求，并使用软件中既有的克隆实例训练机器学习模型。但是，实际的克隆实例无法直接应用于机器学习中。因此，本文提取相应的属性值表示克隆代码实例，即提取代码、上下文两组属性代表克隆创建实例，提取代码属性、上下文属性和演化属性代表克隆变化实例。其中代码属性和上下文属性相似，但从不同的角度表示克隆创建实例和变化实例，克隆创建实例中的属性表示了创建时的被复制和被粘贴代码的特征，变化实例中的属性则表示了发生变化的克隆组的特征。

为表示克隆创建实例，对创建实例的被复制和粘贴克隆代码使用不同的属性。代码属性用于表示被复制的克隆的特征，包括：克隆代码粒度、Halstead属性、结构属性、参数访问数量、总函数调用次数、本地函数调用次数、库函数调用次数、其它调用次数。上下文属性用于表示被粘贴的克隆代码的特征，包括：代码相似度、局部克隆标识、文件名相似度、文件名相似度标识、方法名相似度、总参数名相似度、最大参数名相似度、总参数类型相似度、块信息标识。属性具体信息可以参考本文第二章相关属性值部分（~\ref{lab-creatingattribute}~）。

对于克隆变化实例，从克隆组的角度重新提取了代码属性和上下文属性，并从演化的角度新增演化属性。代码属性从代码自身的角度描述了克隆变化实例中克隆代码特征，包括克隆粒度、代码行平均、Halstead属性平均、结构属性平均、总函数调用次数平均、本地函数调用次数平均、库函数调用次数平均、其它调用次数平均。上下文属性描述了克隆变化实例所在的克隆组的克隆关系特征，包括代码相似度平均、文件名相似度平均、文件名相似度变量、方法名相似度平均、总参数名相似度平均、最大参数名相似度平均、总参数类型相似度平均、块信息标识。历史属性描述了克隆变化实例所在克隆组在克隆变化发生前的历史演化特征，包括变化实例寿命、历史演化模式统计、当前演化模式、历史变化统计。同时，还提供了克隆变化实例的变化属性。
属性具体信息可以参考本文第二章相关属性值部分（~\ref{lab-changingattribute}~）。


\BiSection{克隆一致性预测}
{Predicting Clone Consistency-Requirement}

本文将克隆代码的一致性维护需求问题，转化成了克隆创建实例和克隆变化实例的分类问题，即给定一个克隆实例，判别其是否满足克隆一致性维护需求。为了验证本文方法的有效性，本文使用了五种不同的机器学习方法，并将它们应用于克隆一致性维护需求的预测中。因此，本节先简单介绍所选择的机器学习方法。随后，使用属性化的克隆创建实例和克隆变化实例构建和训练不同的克隆一致性预测模型，并使用训练好的机器学习模型，在克隆代码创建时和变化时预测其一致性维护需求。

\BiSubsection{机器学习方法}
{The Employed Machine Learning Methods}
%{The Brief Introduction for Machine Learning Methods}

在本章的实证研究中，为解决本文所提出的研究问题，使用了五种不同的机器学习方法，即：贝叶斯网络方法（Bayesian Network，简称为BayesNet）\cite{friedman1997bayesian}、朴素贝叶斯方法（Native Bayesian，本文简称为Native）\cite{john1995estimating}，支持向量机方法（Support Vector Machine，简称为SVM）\cite{platt199912} 、K近邻方法(K-Nearest Neighbors，简称为KNN) \cite{aha1991instance}和决策树方法(Decision Tree，本文简称为Tree)\cite{quinlan2014c4}。

（1）贝叶斯网络方法\\
贝叶斯网络是一个是一种概率图型，使用已经观察到的事件来预测将来可能发生的事件\cite{friedman1997bayesian}。关于贝叶斯网络的信息可以参考本文第三章~\ref{lab-bayes}~节贝叶斯网络。

（2）朴素贝叶斯方法\\
朴素贝叶斯方法和贝叶斯网络类似，是运用贝叶斯定理为基础的简单概率分类器。但与贝叶斯网络不同的是，朴素贝叶斯方法的特征之间是强（朴素）独立的，因此称为朴素贝叶斯，即假定样本每个特征与其他特征都不相关。 

（3）支持向量机方法\\
支持向量机是另一种常见的机器学习方法，可以应用在分类与回归问题中。SVM模型将实例表示为空间中的点，并且试图构造一个超平面将不同类的实例（点）间隔开。更正式地来说，支持向量机在高维或无限维空间中构造超平面或超平面集合，可以用于分类问题中。直观来说，分类边界距离最近的训练数据点越远越好，因为这样可以缩小分类器的泛化误差。

以本文的克隆一致性需求分类为例，每一个克隆代码实例会抽象称为高维空间中的一个“点”，空间维数等同于所提取的属性数量。在使用SVM分类克隆实例时，将构造一个超平面分割开两种类别的克隆代码实例。

（4）K近邻方法\\
KNN方法是一种用于分类和回归的非参数统计方法。KNN是一种基于实例的学习方法，是局部近似和将所有计算推迟到分类之后的惰性学习。KNN会推迟对训练数据的建模，直到需要分类样本时才进行。在KNN分类中，输出是一个分类族群。一个实例的分类是由其邻居的“多数表决”确定的，K个最近邻居（k为正整数，通常较小）中最常见的分类决定了赋予该对象的类别。若k = 1，则该对象的类别直接由最近的一个节点赋予。邻居都取自一组已经正确分类（在回归的情况下，指属性值正确）的对象。

以本文克隆一致性预测为例，每一个克隆代码实例是KNN中的一个实例。在进行预测时，被预测的克隆实例的类别，将会有其最近的K个邻居进行表决，从而确定其一致性维护需求。

（5）决策树方法\\
机器学习中另一个常见的分类方法是决策树。决策树是一种简单但是广泛使用的分类器。通过训练数据构建决策树，可以高效的对未知的数据进行分类。决策树代表的是属性值与对象类别之间的一种映射关系。树中每个节点表示某个属性，而每个分叉路径则代表的某个可能的权重，而每个叶结点则对应从根节点到该叶节点所经历的路径所表示的对象的类别。决策树仅有单一输出，若欲有复数输出，可以建立独立的决策树以处理不同输出。

 以克隆一致性需求预测为例，克隆实例所提取的属性即是决策树中的属性，最后的克隆一致性维护需求则是对象的类别。
%决策树（decision tree）是一个树结构（可以是二叉树或非二叉树）。其每个非叶节点表示一个特征属性上的测试，每个分支代表这个特征属性在某个值域上的输出，而每个叶节点存放一个类别。使用决策树进行决策的过程就是从根节点开始，测试待分类项中相应的特征属性，并按照其值选择输出分支，直到到达叶子节点，将叶子节点存放的类别作为决策结果。

\BiSubsection{训练与预测}
{Training and Predicting}
%%%分成两个小节
%\BiSubsection{构建与训练预测器}
%{Building and Training Predictor}
%\BiSection{一致性预测}
%{Predicting Clone Consistency}

接下来，使用收集到的克隆实例训练不同的机器学习模型，并预测克隆代码的一致性维护需求。本章将在两个不同的时刻预测克隆代码的一致性维护需求，分别为为克隆创建时和克隆变化时，因此针对每一种机器学习方法，也会训练两种不同的模型。

本章没有对机器学习方法进行改进和研究，所使用模型的构建和训练通过调用现有机器学习工具包WEKA完成。本文使用WEKA 机器学习工具包内提供的机器学习算法进行一致性维护需求预测工作，通过实验对比上述五种机器学习算法的预测效果，从而帮助程序人员选择最好的机器学习模型。

对于每个软件系统，首先，通过收集系统中所有的克隆实例（创建实例和变化实例），并提取相应的属性，用于构建模型训练所需的数据集。然后，调用WEKA中的机器学习算法，分别构建克隆创建和变化时的预测器。对每一种机器学习方法，将会构建和训练两种模型一起预测克隆代码的一致性维护需求。

根据定义~\ref{def-requirement}~，克隆实例有两种不同的状态：需要一致性维护和不需要一致性维护。因此在进行一致性维护需求预测时，克隆实例也具有两种不同的预测结果：
\begin{itemize}
\item 
需要一致性维护：
若克隆创建实例的预测结果为“需要”，软件开发人员需要谨慎的执行克隆创建操作（复制和粘贴）。因为，该克隆创建实例，在未来演化的过程中可能会引发一致性变化，从而向系统中引入额外的维护代价。\\
若克隆变化实例的预测结果为“需要”，软件开发人员需要检测克隆变化实例所在的克隆组的一致性问题，考虑一致地修改组内其它的克隆代码。因为，该克隆变化实例，在未来演化的过程中可能会引发一致性变化，遗忘这种变化会向系统中引入缺陷，从而降低软件质量。
\item
不需要一致性维护：
若克隆创建实例的预测结果为“不需要”，软件开发人员可以自由的执行克隆创建操作（复制和粘贴），从而节约开发时间提高开发效率。因为，该克隆创建实例，在未来演化的过程中不会引发一致性变化，也不会导致额外的维护代价。\\
若克隆创建实例的预测结果为“不需要”，软件开发人员可以自由的修改克隆变化实例所在克隆组的克隆片段。因为，该克隆变化实例，在未来演化的过程中不会引发一致性变化，也不会导致一致性缺陷。
\end{itemize}


在使用已训练好的模型进行预测时，可以与软件开发过程相结合，将该模型嵌入到软件开发环境中，帮助程序开发人员实现边开发边预测克隆实例的一致性维护需求。首先，在软件开发环境中需监测程序员的复制粘贴操作和对克隆代码的修改，识别由此产生的克隆实例（克隆创建实例和变化实例）。然后，根据上文描述的代码、上下文和演化属性，提取相应的特征表示相应的克隆实例。最后，使用训练好的预测器预测相应克隆实例的一致性维护需求，根据预测结果提醒程序开发人员采取进一步的操作。



%%%当克隆克隆和更改实例发生时，我们打算为开发人员提供克隆一致性要求的这些预测因子。如图所示，这些预测变量可以集成到一个IDE中，如eclipse，可以帮助开发人员在开发阶段维护克隆的克隆和变化。这需要追踪克隆克隆和更改的其他要求，这可以由IDE支持。已经超出了我们的研究范围。当开发人员克隆或更改克隆片段时，已使用提取的属性生成克隆克隆或更改实例，并引用此实例。相关预测器将预测其一致性要求，并根据需要通知开发人员采取措施维护此代码克隆。



\BiSection{基于eclipse的克隆一致性维护需求预测插件}
{An eclipse Plug-in for Clone Consistency-Requirement Prediction}

为了与软件开发过程相结合，本章设计并实现了一个克隆代码的一致性维护需求插件，可以帮助开发人员预测克隆一致性维护需求。所设计的克隆一致性预测插件可以嵌入到软件开发环境中（eclipse），实现边开发、边预测、边维护克隆代码的一致性。基于eclipse的预测插件，可以帮助程序开发人员避免克隆变化导致的一致性维护代价及一致性缺陷，从而帮助提高软件质量和可维护性。

%本文所实现的eclipse插件可以帮助分析Jave语言程序，具有三个基本功能，

\BiSubsection{插件基本模块}
{Three Base Modules for Prediction Plug-in }

为了满足克隆代码的一致性需求预测，本文基于eclipse所设计的插件具有三个基本模块，可以帮助程序开发人员解析用java语言实现的软件系统。三个基本模块分别是：预处理模块、属性提取模块和一致性预测模块\footnote{本文插件目前仅支持基于java语言的源代码，但对于其它语言的扩展也较为容易。}。%预处理模块可以建克隆家系并识别克隆演化模式，从而帮助程序开发人员收集系统中的克隆实例。属性提取模块实现了对克隆实例的表示，可以提取不同的属性组表示相对应的克隆实例。一致性预测模块可以调用机器学习方法实现模型的训练，并预测克隆实例的一致性维护需求。

(1) 预处理模块。

预处理模块可以识别大多数克隆检测工具的结果，并构建克隆家系和识别克隆演化模式，从而实现对系统克隆实例的收集。
首先，需要人工的使用克克隆检测工具检测系统中的所有的克隆代码，并将检测结果作为插件的输入。 （本文中使用的克隆检测工具是NiCad \cite {roy2008clone}）
对于软件系统的每一个版本，克隆代码将会被组成克隆组的形式，并使用文件名、起始行号表示所有的克隆代码，即“{\tt file \_name}”、“{\tt start \_line}”和“{\tt end \_line}”。然后，使用CRD重新描述克隆代码并重新组织为新的数据结构，从而方便构建克隆家系。最后，本插件将基于CRD对所有版本中的克隆代码，构建构建系统的克隆家系，并识别克隆演化模式。方法参加本文克隆家系构建和模式识别部分。
根据所构建的克隆家系和识别的演化模式，可以方便的获取系统中已经存在的克隆创建和变化实例。值得注意的是，构建克隆家系时需要系统所有版本的源代码，用于生成克隆代码的CRD表示。

(2) 属性提取模块

属性提取模块将不同的克隆代码实例抽象成相应的属性值，对克隆创建实例提取代码属性和上下文属性，对克隆变化实例提取代码属性、上下文属性、演化属性和变化情况。首先，代码属性和上下文属性提取，可以使用抽象语法树（Abstract Syntactic Tree，AST）对程序源代码进行解析获取。对每一个克隆代码以及克隆代码所在文件，使用Eclipse AST中的 ASTParser类将克隆片段所在源代码解析成AST\footnote{抽象语法树可参见：http://www.eclipse.org/articles/Article-JavaCodeManipulation\_AST/}。通过遍历语法树访问相应关键节点，根据本文描述的属性值计算克隆实例的代码属性和上下文属性。然后，历史属性提取，历史属性提取通过遍历克隆实例的克隆家系，根据属性描述计算相应历史属性。值得注意的是，属性提取时同样需要系统所有版本的源代码，用于生成克隆代码的抽象语法树和属性计算。%对克隆代码提取的工作可参见论文。\cite{yuan}


(3) 克隆一致性预测模块。

一致性预测模块实现了对相关机器学习模型的训练，并可以对在软件开发过程新产生的克隆创建实例和变化实例进行一致性维护需求预测。本插件并没有具体实现机器学习方法，而是通过调用WEKA中的API完成对机器学习模型的构造、训练和预测功能。WEKA是一个Java语言实现的数据挖掘和机器学习开源工具。WEKA提供了丰富的接口帮助程序开发人员调用相关的机器学习方法，可以使用极为灵活的方式对机器学习模型进行训练和预测\footnote{使用WEKA可参见：http://weka.wikispaces.com/。}。


\BiSubsection{克隆实例跟踪}
{Tracking Clone Instance in eclipse }

在软件开发过程中预测克隆代码的一致性需求维护，还需要实时的捕获软件中产生的克隆实例，即跟踪克隆实例的产生（克隆创建实例和克隆变化实例）。

（1）克隆创建实例跟踪

研究表明，软件中的克隆代码主要是由于复制和粘贴操作导致，即克隆创建实例产生的直接原因是程序开发人员的复制和粘贴操作。因此，测复制和粘贴操作即可跟踪克隆创建实例的产生。

%可以参考论文\cite{yuanD大论文}的实现

为在eclipse中监测程序开发人员的复制粘贴操作，


（2）克隆变化实例跟踪

为了跟踪克隆变化的产生，需要实现跟踪系统中克隆代码以及变化。


Tracking clones changes

\BiSubsection{克隆一致性预测插件使用}
{Three Base Modules for Prediction Plug-in }

由于机器学习模型的构建和训练往往需要大量的时间，不应该也不需要在每次开发时训练机器学习模型。因此，在实际的开发过程中，模型的训练和预测是分开进行的。
%因此，在使用一致性需求插件进行预测时，开发人员应该提前构建和训练好预测模型。

为了更为灵活的使用本文方法，提供两种构建和训练预测模型的方式。
第一个是用项目本身的历史数据来训练预测模型。在这种情况下，本文的插件首先调用预处理模块，构建项目本身所有克隆家系和收集项目中的所有克隆实例。然后调用属性提取模块，将提取收集到的克隆实例的属性值，并生成训练集。最后，使用该训练集建立和训练克隆一致性预测模型。
第二个其它项目数据作为训练集。原因在于，对于某些项目而言，由于实际版本的限制，其历史的克隆实例可能较少，不足以较好的训练所需要的模型。因此，需要使用其它项目的历史数据作为训练集。需要注意的是，随着时间的推移，当项目自身可以收集到足够的数据时，建议开发人员重新使用项目自身的数据训练机器学习模型，从而达到较好的预测效果。

当监测到具体的克隆实例产生时，调用已经训练好的机器学习模型进行预测。软件开发过程中，监测到克隆实例产生时，调用属性提取模块提取本次实例的属性，并使用训练好的一致性模型预测其一致性，根据预测结果通知程序开发人员采取相应措施。值得注意的是，在实际预测时，克隆变化实例预测需要项目的历史版本源代码，因为历史属性中包含克隆变化实例的历史变化过程。为了轻量化预测过程，程序开发人员可以将克隆变化实例中的历史变化属性移除。


\BiSection{实验结果与分析}
{Experiments Results and Analysis}

本节给出本章的实验结果与分析，使用五种不同的机器学习方法，对克隆代码创建时和变化时同时进行一致性维护预测。首先简单介绍了实验所使用的实验系统和评估方法，然后详细给出每个实验的结果与分析。


\BiSubsection{实验系统与实验设置}
{Experimental Projects and Methodology}

为了解决本章的研究问题，本章在四个开源项目上进行了实验。表~\ref{instancesta}~给出了实验系统中克隆实例的统计信息，包括克隆创建实例和克隆变化实例。从该表可以看出，系统中克隆创建实例的数量要多于克隆变化实例的数量。克隆创建实例的数量范围为633到3666个，克隆变化实例的数量范围在159到1040个，系统jEdit是克隆规模最小的系统。表中第3和4列给出了不需要和需要一致性维护的克隆实例的数量和比例。不需要一致性维护的克隆实例，在其未来的演化中不会导致一致性变化和额外的维护代价。需要一致性维护的克隆实例，在其演化过程中可能导致一致性变化及克隆一致性缺陷。


%We conduct our experiments on {four} open source projects for this clone consistency prediction task. Table~\ref{projects}~ shows the details of these projects with the clone-creating and clone-changing instances.  As observed from this table, number of clone-creating instances ranges from 633 to 3,666, and that of clone-changing instances ranges between 159 and 1,040, with project {\em jEdit} being the smallest repository in both scenarios. Specifically, the numbers of two types of clone instances which meet consistency-requirement (ie., leading to some form of consistent change of clone groups in the future) are shown in column 3 and column 6, whereas columns 2 and 5 reflect the numbers of clone instances that are consistency-requirement {\em free} (ie., do {\em not\/} lead to any consistent change in the future). 


\begin{table}[htbp]
\bicaption[instancesta]{}{实验系统的克隆实例信息统计}
{Table$\!$}{The statistics for clone instances in four projects}
\vspace{0.5em}
\centering
\wuhao
\begin{tabular}{ccccc}
\toprule[1.5pt]
~\multirow{2}{*}{类型}&\multirow{2}{*}{系统}&{不需要}&{需要} &\multirow{2}{*}{总数}\\
~&~&{一致性维护}&{一致性维护}&~\\
%~\multirow{2}{*}{\textbf{Instances}}&\multirow{2}{*}{\textbf{Project}}&\textbf{Consistency-} &\textbf{Meeting} &\multirow{2}{*}{\textbf{Total}}\\
%~&~&\textbf{Requirement Free}&\textbf{Consistency-Requirement}&~\\
\midrule[1pt]
\multirow{4}{*}{克隆创建实例}
&ArgoUML&	2574(77.07\%)&	766(22.93\%)&	3340\\
&jEdit&560(88.47\%)&	73(11.53\%)&	633\\
&jFreeChart&	2013(59.80\%)&	1353(40.20\%)&	3366\\
&Tuxguitar&	1016(71.10\%)&	413(28.90\%)&	1429\\
\hline
\multirow{4}{*}{克隆变化实例}
&ArgoUML&288(67.45\%)&139(32.55\%)&427\\
&jEdit&78(49.06\%)&81(50.94\%)&159\\
&jFreeChart&452(43.46\%)&588(56.54\%)&1040\\
&Tuxguitar&91(25.71\%)&263(74.29\%)&354\\
\bottomrule[1.5pt]
\end{tabular}
\end{table}

从表~\ref{instancesta}~中可以观察到两个现象。第一，软件系统中存在大量的克隆创建实例（三个项目中有上千的例子），同时大部分的克隆创建实例在其演化过程中不满足一致性维护要求(比例从59.8\%到88.47\%)。这表明克隆创建操作（即复制和粘贴操作）已经成为开发人员的常用技术，并且它们中的大多数在演化过程中不会在将来引入任何一致的变化，建议开发人员可以使用复制和粘贴操作节省开发时间。第二，在克隆变化实例中，三个系统中只有数百个变化实例，仅有jFreeChart中有1040变化实例。这表明相对于克隆代码在演化过程中不会频繁地发生变化，但也有相当数量的变化。值得注意的，这些变化中需要一致性维护的变化实例比例占相当大的一部分，其比例为33\%到74 \%。克隆代码的一致性变化更容易引发一致性变化，从而导致增加克隆代码一致性缺陷的风险，因此开发人员在软件开发过程中应该更加注意软件开发过程中的克隆变化。

%We have two observations for clone instances from Table~\ref{projects}.
%\begin{enumerate}
%\item For clone-creating instances, there are thousands of creating instances from {\em three projects\/}, and more than half-a-thousand for{\em jEdit\/}.Among them, only a small percentage of them meeting consistency-requirement, ranging from 12\% to 40\%. This shows that clone-creating operation (ie., copy-and-paste operation) have become a common development technique, but the majority of them will not introduce any consistent change in the future, indicating that developers usually apply copy-and-paste technique to save development time.
  
%\item On the other hand, for changing instances, there only have hundreds of instances from {\em three\/} projects, and 1,040 counts from {\em jFreeChart\/}, indicating that these clones do not change frequently in evolution.Nonetheless, the percentage of changing instances that meets consistency-requirement ranges from 33\% to 74\% , indicating that there still have hundreds of opportunity of clone consistency-defect arising form these consistent changes of clone-changing instance in the software. Hence, developers should pay more attention on clone changing during software development time.
%\end{enumerate}


本章对克隆代码的一致性需求预测进行实证研究，目的是解决本文提出的研究问题：克隆代码的一致性维护需求预测是否可以应用于其它的机器学习方法中，软件开发人员应如何结合软件开发过程中执行克隆一致性需求预测？

本章将此研究问题划分为三个子问题，因此实验也相应的划分为三个部分以回答三个子问题。对于第一个研究问题，进行了“克隆代码创建时一致性预测实验”，用于验证五种不同机器学习方法对克隆代码创建时一致性预测的有效性。类似地，为了回答第二个研究问题，本章设计了“克隆代码变化时一致性预测”实验。对克隆变化实例进行实验，也分析了五种不同的机器学习方法在克隆变化实例上的有效性。最后，第三个研究问题没有具体的实验，但通过结合软件开发过程，并对比克隆创建实验和变化实验，回答了本章提出的第三个研究问题。同时，给出了一些相关的建议，帮助程序开发人员在开发实践中使用这些预测模型和技术。
%In this empirical study, we aim to address our research problem with three detailed sub research questions; as such, our experiments are divided into three parts respectively.For the first research question, we construct {\em clone creating experiment\/} for creating instances that reports on the effectiveness of the {\em five} different machine learning methods.Secondly, {\em clone changing experiment\/} is built for second research question with these methods.Finally, we compare and contrast the above two experiments for clone-creation and clone-change respectively, in order to answer the third research question. We provide our recommendations for developers on how to apply these change-consistency predictive task in practice based on the investigations of the above two experiments.


在克隆创建实验和克隆变化实验中，与本文第三章和第四章相似，又分别进行了两种实验\footnote{值得注意的是，本章没有进行交叉验证实验。}：全属性实验和属性组实验，从两个不同的角度评估五种机器学习方法的有效性。全属性实验，使用所提取的全部属性进行预测，并对比五种机器学习方法。属性组实验中，使用不同的属性组进行实验，分析不同属性组在五种不同机器学习方法上的预测能力。
%Similar to the works performed in \cite{wang2014predicting}\cite{zhang2016predicting},  we assess the effectiveness of this prediction from two different perspectives:
%\begin{enumerate}
%\item {\em Effectiveness Experiment\/}: We utilize all attributes extracted from each of the four projects with different machine learning methods to assess the quality of the prediction.
%\item {\em Attribute Set Experiment\/}: We assess the impact of each of the contributing attribute sets with different machine learning methods on the prediction.
%\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%以下是详细的所有实验细节。
%%%放弃不用
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%与第三章和第四章类似，克隆变化实例有两种类别，即需要一致性维护实例和不需要一致性维护实例。本章还从上述两个角度对本文方法进行了评估，进一步将实验划分为需要一致性维护实验和不需要一致性维护实验。“需要一致性维护实验”，分析了不同机器学习方法对满足一致性维护需求的实例的预测能力。与之相反，“不需要一致性实验”，分析了不同机器学习方法对不满足一致性维护需求的实例的预测能力。这些满足维护需求的克隆实例，将导致未来的一致变化。当实例刚发生时，应该警告开发人员采取一定的措施。另一方面，不满足一致性需求的实例，将不会导致一致性变化，因此开发人员可以自由地自行复制或更改代码。

%为了评测每一个实验结果，本文采用三个度量值评估预测效果，分别是：准确率（Precision）、召回率（Recall）和F值（F-measure）。其中，准确率和召回率的计算方式与第三章和第四章中一致，F值则权衡了两种度量，其计算方式如下，
%\[
% F-measure =2 \cdot {\frac {{precision} \cdot {recall} }{ {precision} + {recall} }}
%\]
% 在满足一致性的实验中。同时，为了给出给出更一般性的评估，并将两种克隆实例归并到一起，从而分析机器学习模型的一般化预测能力。采用平均精确度（Average Precision）、平均召回率（Average Recall）和平均F值（Average F-measure）。


%我们的案例研究中，采用五种机器学习方法来探索这四个项目的这些预测的有效性。我们没有意图改进这些方法来适应这种一致性要求的预测。
%因此，我们使用包装WEKA来建立和训练我们所有需要的预测模型与不同的机器学习方法。WEKA是一种非常灵活且易于使用的数据挖掘工具，其中包含大量的分类/预测方法\cite{hall2009weka}。在本节中，我们将使用每种机器学习方法的缩写术语，贝叶斯网络为{\em BayesNet}，本机贝叶斯为{\em Native}，支持向量机为{\em SVM}，K最近邻居作为{\em KNN}和设计树作为{\em 树}详细。
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

在每一个实验中，本章使用五种不同的机器学习方法，并同时对需要一致性维护的克隆实例和不需要一致性维护的克隆实例进行预测。在实验中，首先，将数据集分为10个数据集作10倍交叉验证，用于评估预测效果。然后，分别计算满足一致性维护需求和不满足一致性维护需求的准确率（Precision）、召回率（Recall）和F值（F-measure），用于评估不同类型实例的预测效果。最后，将这两组预测结果进行加权平均，使用平均准确率、平均召回率和平均F值作为实验指标，评估预测模型的预测能力。
%Each of the prediction models is trained to predict both consistency-requirement and consistent-requirement free at the same time. All data are divided into 10 cross-validation set, as normally done in such experiment.We evaluate the prediction effectiveness of each of the models by first calculating the precisions, recalls, and f-measures for them predicting the consistency and free instances respectively. Then, we calculate the combined average precision, recall and f-measure from these two results.

因此，对克隆创建实例和克隆变化实例的评价指标为：准确率、召回率和F值，如下所示：
%To evaluate the effectiveness of each prediction for clone-creating and changing instances, we employ three different metrics, as follows:

\begin{itemize}
\item
{准确率（Precision）：} 该指标评估克隆实例一致性维护需求预测的准确程度，包含了满足和不满足一致性维护需求的实例。首先，计算预测中满足一致性维护需求的克隆实例的准确率``$P_1$''，即预测为满足一致性维护需求的克隆实例中正确预测的数量与全部预测数量的比值。然后，相似的计算不满足一致性维护需求克隆实例的准确率``$P_2$''。最后，将这两个值进行加权平均，作为整个模型的准确率。 ``$P_1$'' 是满足一致性维护需求的准确率，并且训练集中所有满足一致性的实例数量为``$N_1$'' ；类似地， ``$P_2$''为不满足一致性维护需求的准确率，且 ``$N_2$''为实例数量。平均准确率（Average Precision）计算如下,
\[
\mbox{\it Ave-Precision} ~=~ {\frac {P_1 \times N_1 + P_2 \times N_2}{N_1 + N_2}}
\]
在实验中，使用此 ``Average Precision'' 作为模型准确率（Precision）。


\item
{召回率（Recall）：} 该指标评估克隆实例一致性维护预测的查全能力，包含了满足一致性维护需求和不满足一致性维护需求的实例。同准确率，分别计算满足和不满足一致性维护需求的实例的召回率，然后对两者进行加权平均。$R_1$'' 是满足一致性维护需求的召回率，并且训练集中所有满足一致性的实例数量为``$N_1$'' ；类似地， ``$R_2$''为不满足一致性维护需求的召回率，且 ``$N_2$''为实例数量。平均召回率（Average Recall）计算如下,
\[
\mbox{\it Ave-Recall} ~=~ {\frac  {R_1 \times N_1 + R_2 \times N_2}{N_1 + N_2}}.
\]
在实验中，使用此 ``Average Recall'' 作为模型召回率（Recall）。

\item
{F值（F-measure）：} 该指标可以评估所有克隆实例的准确率和召回率的平均有效性。相似地，先分别计算满足和不满足一致性维护需求的克隆实例的F值，然后根据实例的数量进行加权平均。给定一个预测的准确率为precision、召回率为 recall，则该预测的F-Measure可计算如下,
\[  
\mbox{\it F-measure} =2 \times {\frac {\mbox{\it precision} \times \mbox{\it recall} }{ \mbox{\it precision} + \mbox{\it recall} } }
\]
为计算本章预测的平均F-measure， ``$F_1$'' 是满足一致性维护需求的克隆实例的F值，且实例的个数为``$N_1$''；``$F_2$'' 是不满足一致性维护需求的克隆实例的F值，且实例的个数为``$N_1$''，则平均F值（Average F-measure） 可计算如下,
\[
\mbox{\it Ave-F-measure} ~=~ {\frac  {F_1 \times N_1 + F_2 \times N_2}{N_1 + N_2}}.
\]
在实验中，使用此 ``Average F-measure'' 作为模型F值（F-measure）。
\end{itemize}

%\begin{itemize}
%\item
%{\bf Precision:} This assesses the accuracy of the model in predicting if a clone instance meet the consistency-requirement and free.  Specifically, we first compute the ratio of the number of {\em correct} predictions of clone instances meeting consistency-requirement to the number of predictions made by the model about instances meeting consistency-requirement. Then, we compute similar ratio for consistency-free. Taking clone-creating prediction as an example, we have two precision values, ``$P_1$'' is for meeting consistency instances with number of  ``$N_1$'' and ``$P_2$'' is for consistency-free instances with number ``$N_2$''. The average precision for clone-creating prediction is computed as follows,
%\[
%\mbox{\it Ave-Precision} ~=~ {\frac {P_1 \times N_1 + P_2 \times N_2}{N_1 + N_2}}
%\]
%We employ this ``Average Precision'' as the assessing metric ``{\bf Precision} '' for this prediction.
%\item
%{\bf Recall:} This assesses the effectiveness of the model in discovering all clone instances meeting either consistency-requirement or free. We similarly compute two different {\em recalls\/}  corresponding to two categories -- consistent-requirement and consistent-requirement free -- of clone instances, then calculate the {\em average recall\/} according to their weight of each clone category's counts. Specifically, the first recall is computed as the ratio of the number of {\em correct} predictions of clone instances meeting consistency-requirement to total number of clone instances meeting consistency-requirement (i.e., ground truth). Taking clone-creating prediction as an example, we have two recall values, ``$R_1$'' is for meeting consistency instances with number of  ``$N_1$'' and ``$R_2$'' is for consistency-free instances with number ``$N_2$''. The average recall for this clone-creating prediction is computed as follows,
%\[
%\mbox{\it Ave-Recall} ~=~ {\frac  {R_1 \times N_1 + R_2 \times N_2}{N_1 + N_2}}.
%\]
%We employ this ``Average Recall'' as the assessing metric ``{\bf Recall} '' for this prediction.
%\item
%  {\bf F-measure:} This assesses the weighted average effectiveness of the precision and recall both for all clone instances. It is a measure of the prediction's accuracy. We compare the {\em average F-Measure\/} for both two categories of clone instances according to  their weight of each category's counts. Given the precision and the recall value of a prediction for one of the two categories of clone instances, the {\em F-Measure} is computed as follows,
%\[  
%\mbox{\it F-measure} =2 \times {\frac {\mbox{\it precision} \times \mbox{\it recall} }{ \mbox{\it precision} + \mbox{\it recall} } }
%\]
%Taking clone-creating prediction as an example, we have two F-measure values, ``$F_1$'' is for meeting consistency instances with number of  ``$N_1$'' and ``$F_2$'' is for consistency-free instances with number ``$N_2$''. The average F-measure for this clone-creating prediction is computed as follows,
%\[
%\mbox{\it Ave-F-measure} ~=~ {\frac  {F_1 \times N_1 + F_2 \times N_2}{N_1 + N_2}}.
%\]
%We employ this ``Average F-measure'' as the assessing metric ``{\bf F-measure} ''for this prediction.
%\end{itemize}

%在本章的实证研究中，使用五种不同的机器学习方法来验证预测帮助程序开发人员选择合适的机器学习模型。值得注意的是，本文没有对机器学习方法本身做进一步的改进。在培训这五种型号时，必须进行一些设置。大多数这些设置默认设置在WEKA中，无需进一步调整。这意味着有可能进一步增强这些方法的有效性的机会。在我们的实验中，例如，{\ em BayesNet}被训练为克隆创建实例的父节点数设置为3，克隆更改为4。 {\ em Native}只有一个父节点。这两个模型都使用0.5作为两个一致性标签的阈值 - 默认设置为{\ em WEKA}。对于{\ em SVM \ /}方法，我们使用{\ em多项式内核\ /}作为内核函数。对于{\ em Tree \ /}，我们使用具有0.75置信因子的J48算法。在{\ em KNN \ /}中，我们使用欧几里德距离作为距离函数与1个邻居进行预测。

%In this study, five machine learning methods are employed to determine their effectiveness in performing predictions.We use the package named {\em WEKA\/} to build and train each of the prediction models for {\em five\/} different machine learning methods. WEKA is a very flexible and easy-to-use data mining tool which contains plenty of methods for prediction\cite{hall2009weka}. In this section, we use abbreviations for each of machine learning methods, denoting Bayesian network as {\em BayesNet\/}, Native Bayes as {\em Native\/}, Support Vector Machine as {\em SVM\/}, K-Nearest Neighbors as {\em KNN\/} and Design Tree as {\em Tree\/}.
%Some settings are necessary when these five models are trained. Most of these settings are set by default in WEKA, without further adjustment. This means that there might be further opportunity for enhancement made to the effectiveness of these methods. In our experiment, {\em BayesNet}, for example, is trained with the number of parent node set to 3 for clone-creating instance and 4 for clone-changing. {\em Native} only has one parent node. Both these models use 0.5 as the threshold for the two consistency labels -- a default set by {\em WEKA}. for the {\em SVM\/} method, we employed {\em polynomial kernel\/} as the kernel function.  For {\em Tree\/}, we employed the J48 algorithm with 0.75 confidence factor. In {\em KNN\/}, we use the euclidean distance as the distance function with 1 neighbor for the prediction.

\BiSubsection{克隆创建时一致性预测}
{Experiments for Clone Consistency-Requirement}

在本实验中，我们解决了克隆克隆实例的第一个子研究问题。
 子问题1：
在克隆克隆时间，其他机器学习方法是否可以用于克隆一致性要求预测？
属性集是否对此预测产生积极或消极的影响？

我们采用五种不同的机器学习方法来预测这四个项目的克隆创建时的克隆代码的一致性维护需求，实验结果如表\ref{creatingallavg}~和~\ref{creatingsetavg}~所示。

%\begin{table}[htbp]
%\bicaption[creatingallfree]{}{克隆创建实例的一致性维护自由的预测效果}
%{Table$\!$}{The Effectiveness of Creating Instances for Consistency-Free}
%\vspace{0.5em}
%\centering
%\wuhao
%\begin{tabular}{cccccc}
%\toprule[1.5pt]
%{\textbf{Metric}}&{\textbf{Method}}&{\textbf{ArgoUML}}&{\textbf{jEdit}}&{\textbf{jFreeChart}}&{\textbf{Tuxguitar}}\\
%\midrule[1pt]
%\multirow{5}{*}{Percision}
%&{BayesNet	}&0.945	&0.943	&0.879	&0.861\\
%&{Natvie	}&0.917	&0.941	&0.863	&0.853\\
%&{SVM}&	0.955	&0.919	&0.889	&0.872\\
%&{KNN}&	0.96	&0.933	&0.905&	0.891\\
%&{J48}&	0.953&	0.936	&0.891	&0.913\\
%\hline
%\multirow{5}{*}{Recall}
%&{BayesNet}&	0.974&	0.916&	0.932	&0.917\\
%&{Natvie	}&0.94&	0.85&	0.927	&0.858\\
%&{SVM}&	0.992	&0.998	&0.959&	0.979\\
%&{KNN}&	0.962&	0.943	&0.93	&0.896\\
%&{J48}&	0.969&	0.959&	0.934&	0.935\\
%\hline
%\multirow{5}{*}{F-Measure}
%&{BayesNet}&	0.959	&0.929&	0.905&	0.888\\
%&{Natvie	}&0.928	&0.893	&0.894	&0.856\\
%&{SVM}&	0.973	&0.957&	0.923	&0.923\\
%&{KNN}&	0.961&	0.938	&0.917	&0.893\\
%&{J48}&     0.961&	0.947	&0.912&	0.924\\
%\bottomrule[1.5pt]
%\end{tabular}
%\end{table}

%\begin{table}[htbp]
%\bicaption[creatingallmeeting]{}{克隆创建实例的一致性维护需求的预测效果}{Table$\!$}
%{The Effectiveness of Creating Instances for Meeting Consistency-Requirement}
%\vspace{0.5em}
%\wuhao
%\centering
%\begin{tabular}{cccccc}
%\toprule[1.5pt]
%{\textbf{Metric}}&{\textbf{Method}}&{\textbf{ArgoUML}}&{\textbf{jEdit}}&{\textbf{jFreeChart}}&{\textbf{Tuxguitar}}\\
%\midrule[1pt]
%\multirow{5}{*}{Percision}
%&{BayesNet}&	0.808	&0.575	&0.809	&0.637\\
%&{Natvie}&	0.714	&0.589	&0.78	&0.637\\
%&{SVM}&	0.845	&0.329	&0.823	&0.646\\
%&{KNN}&	0.864	&0.479	&0.854	&0.731\\
%&{J48}&	0.841	&0.493	&0.831	&0.782\\
%\hline
%\multirow{5}{*}{Recall}
%&{BayesNet}&	0.902	&0.472	&0.889	&0.758\\
%&{Natvie}&	0.78	&0.339	&0.878	&0.646\\
%&{SVM}&	0.969	&0.96	&0.931	&0.927\\
%&{KNN}&	0.872	&0.522	&0.892	&0.74\\
%&{J48}&	0.891	&0.61	&0.894	&0.83\\
%\hline
%\multirow{5}{*}{F-Measure}
%&{BayesNet}&	0.853	&0.519	&0.847	&0.692\\
%&{Natvie}&	0.746	&0.43	&0.826	&0.641\\
%&{SVM}&	0.902	&0.49	&0.873	&0.762\\
%&{KNN}&	0.902	&0.49	&0.873	&0.762\\
%&{J48}&	0.865	&0.545	&0.861	&0.805\\
%\bottomrule[1.5pt]
%\end{tabular}
%\end{table}


\begin{table}[htbp]
\bicaption[creatingallavg]{}{克隆创建实例一致性维护需求平均预测效果}
{Table$\!$}{The Average Effectiveness of Creating Instances for Consistency-Requirement}
\vspace{0.5em}
\centering
\wuhao
\begin{tabular}{cccccc}
\toprule[1.5pt]
{指标}&{方法}&{{ArgoUML}}&{{jEdit}}&{{jFreeChart}}&{{Tuxguitar}}\\
%{\textbf{Metric}}&{\textbf{Method}}&{\textbf{ArgoUML}}&{\textbf{jEdit}}&{\textbf{jFreeChart}}&{\textbf{Tuxguitar}}\\
\midrule[1pt]
\multirow{5}{*}{Percision}
&{BayesNet}&0.935&0.889&0.883&	0.831\\
&{Native}&	0.886&	0.871&	0.869&	0.793\\
&{SVM}&0.958&	0.924&0.906&0.888\\
&{KNN}&	0.94&0.886&0.9&	0.848\\
&{Tree}	&0.939&0.898	&0.893&0.889\\
\hline
\multirow{5}{*}{Recall}
&{BayesNet}& 0.936&	0.877&	0.882&	0.836\\
&{Native}&0.888&0.82&	0.868&0.794\\
&{SVM}& 0.958&0.921&0.904&0.883\\
&{KNN}&0.94&0.889&	0.9	&0.848\\
&{Tree}&0.94	&0.905&	0.892&0.891\\
\hline
\multirow{5}{*}{F-measure}
&{BayesNet}&0.935&0.882&0.881&0.832\\
&{Native}&0.887&	0.84&0.867&0.794\\
&{SVM}&0.957&	0.903	&0.903&0.876\\
&{KNN}&0.94&0.887&	0.9	&	0.848\\
&{Tree}	&0.939&	0.901	&0.892&0.89\\
\bottomrule[1.5pt]
\end{tabular}
\end{table}

表~\ref{creatingallavg}~给出了克隆创建实例的使用全部属性组的预测结果。从表中可以看出，五种不同的机器学习方法均可以高效地预测克隆一致性要求，准确率从79.3\%到95.8\%，召回率从79.4\%到95.8\% ，F值从79.4\%至95.7\%。同时，对比不同机器学习方法的有效性，通过对比发现，SVM在这四个实验系统上具有最佳的预测能力。具体来说，SVM在系统 ArgoUML、jEdit和jFreeChart上有最好的结果。对于{Tuxguitar}系统来说，决策树具有最好的结果，SVM具有第二好的预测结果。与此同时，贝叶斯网络和朴素贝叶斯方法在这四个项目中几乎具有相对较差的预测结果，但是相差并不明显。
因此，建议开发人员在需要预测克隆创建实例时首先考虑SVM，其它的机器学习方法也可以作为选择进行考虑。

%Table~\ref{creatingall} depicts the effectiveness of clone-creating instances' prediction.From this table, we observe that all five models {\em effectively} predict consistency-requirement for clone-creating instances, having precisions range from 79.3\% to 95.8\%, recalls from 79.4\% to 95.8\%, and F-measure from 79.4\% to 95.7\%.By contrasing the effectiveness among these different learning methods, it is clear that {\em SVM\/} has slightly better ability of prediction than the other methods for four projects.Specifically, SVM has the best results for{\em ArgoUML, jEdit and jFreeChart}, Decision Tree has the best results and SVM has the second best for {\em Tuxguitar}.At the same time, Bayesian Network and Native Bayes almost always hold relatively worse-off prediction results on these four projects.Therefore, we conclude that {\em SVM\/} has good predictive ability -- among these five machine learning models -- for clone creating consistency prediction.

\begin{sidewaystable} [htbp]
\bicaption[creatingsetavg]{}{克隆创建实例的属性组平均预测效果}
{Table$\!$}
{The Average Effectiveness of Attribute Set on Creating Instances for Consistency-Requirement}
\vspace{0.5em}
\centering
\wuhao
\begin{tabular}{cccccccccccccc}
\toprule[1.5pt]
\multirow{2}{*}{指标}&\multirow{2}{*}{方法}&\multicolumn{3}{c}{\textbf{ArgoUML}}&\multicolumn{3}{c}{\textbf{jEdit}}&\multicolumn{3}{c}{\textbf{jFreeChart}}&\multicolumn{3}{c}{\textbf{Tuxguitar}}\\
\cline{3-14}
&&\textbf{All}&\textbf{Code}&\textbf{Context}&\textbf{All}&\textbf{Code}&\textbf{Context}&\textbf{All}&\textbf{Code}&\textbf{Context}&\textbf{All}&\textbf{Code}&\textbf{Context}~\\
%\multirow{2}{*}{\textbf{Metric}}&\multirow{2}{*}{\textbf{Method}}&\multicolumn{3}{c}{\textbf{ArgoUML}}&\multicolumn{3}{c}{\textbf{jEdit}}&\multicolumn{3}{c}{\textbf{jFreeChart}}&\multicolumn{3}{c}{\textbf{Tuxguitar}}\\
%\cline{3-14}
%&&\textbf{All}&\textbf{Code}&\textbf{Context}&\textbf{All}&\textbf{Code}&\textbf{Context}&\textbf{All}&\textbf{Code}&\textbf{Context}&\textbf{All}&\textbf{Code}&\textbf{Context}~\\
\midrule[1pt]
\multirow{5}{*}{Percision}
&BayesNet&	0.935&	0.912&	0.917&		0.889&	0.885&	0.83&		0.883&	0.808&	0.903&		0.831&	0.811&	0.843\\
&Native&	0.886&	0.866&	0.877&		0.871&	0.865&	0.832&		0.869&	0.755&	0.873&		0.793&	0.747&	0.824\\
&SVM&	0.958&	0.928&	0.942&		0.924&	0.924&	0.909&		0.906&	0.819&	0.906&		0.888&	0.834&	0.873\\
&KNN&	0.94&	0.911&	0.933&		0.886&	0.903&	0.877&		0.9	&0.808&	0.898&		0.848&	0.806&	0.861\\
&Tree&	0.939&	0.904&	0.93&		0.898&	0.882&	0.876&		0.893&	0.802&	0.891&		0.889&	0.8&	0.881\\
\hline
\multirow{5}{*}{Recall}
&BayesNet&	0.936&	0.914&	0.919&		0.877&	0.869&	0.852&		0.882&	0.803&	0.903&		0.836&	0.817&	0.846\\
&Native&	0.888&	0.868&	0.88&		0.82&	0.836&	0.826&		0.868&	0.752&	0.873&		0.794&	0.756&	0.816\\
&SVM&	0.958&	0.929&	0.943&		0.921&	0.921&	0.918&		0.904&	0.806&	0.904&		0.883&	0.837&	0.874\\
&KNN&	0.94&	0.912&	0.934&		0.889&	0.912&	0.885&		0.9&	0.803&	0.898&		0.848&	0.81&	0.862\\
&Tree&	0.94&	0.905&	0.931&		0.905&	0.896&	0.889&		0.892&	0.796&	0.89&		0.891&	0.807&	0.882\\
\hline
\multirow{5}{*}{F-measure}
&BayesNet&	0.935&	0.912&	0.917&		0.882&	0.876&	0.84&		0.881&	0.797&	0.902&		0.832&	0.811&	0.844\\
&Native&	0.887&	0.867&	0.878&		0.84&	0.848&	0.829&		0.867&	0.741&	0.872&		0.794&	0.75&	0.819\\
&SVM&	0.957&	0.927&	0.941&		0.903&	0.903&	0.907&		0.903&	0.797&	0.903&		0.876&	0.827&	0.869\\
&KNN&	0.94&	0.912&	0.933&		0.887&	0.905&	0.881&		0.9&	0.796&	0.897&		0.848&	0.807&	0.862\\
&Tree&	0.939&	0.904&	0.93&		0.901&	0.887&	0.881&		0.892&	0.788&	0.889&		0.89&	0.802&	0.881\\
\bottomrule[1.5pt]
\end{tabular}
\end{sidewaystable} 


为了探索不同属性组对预测效果的影响，在五个机器学习方法上进行了属性组实验，实验结果如表~\ref{creatingsetavg}~所示。表中“全部”列是全部属性实验结果，属性组实验结果在“代码”列和“上下文”列中。

从这个表中可以看出，属性组实验结果和全部属性组实验结果没有显着差异。这表明所使用的属性组不会对克隆创建时一致性预测产生负面影响。尽管如此，在全部实验结果中，效果最差的实验结果往往出现在属性组的实验结果中，即在仅使用代码属性或仅适用上下属属性预测时。具体来说，对系统ArgoUML、 jFreeChart和 Tuxguitar，其仅使用代码属性进行预测时五种机器学习方法的预测效果最差；而对系统jEdit仅仅使用“上下文” 属性的五种机器学习方法预测效果最差。

最后，分析不同机器学习方法之间的预测能力，可以得出与全属性实验相似的结论，即五种机器学习方法的预测能力相差不大，但SVM方法具有相对最好的预测能力。因此建议程序开发人员在预测时保留所有的属性，并优先选择SVM方法。


%To explore the significance of each extracted attribute set, we alter the experiments by {\em employing only one} attribute set for consistency prediction. The results for the effectiveness of attributes set are shown in Table~\ref{creatingset}. In this table, we use ``All'' columns to record the results when all attribute sets are used, and ``Code'', ``Context'' respectively for the case when only one attribute set is used. From this table, we observe that there dose not have the significant different results among these three predictions using individual attribute set. This revelation indicates that our attribute sets {\em do not\/} play any negative impact on our prediction. Nevertheless, we also can see that most of the relatively worst prediction results exist in the ``Attribute'' columns (only code or context) for all these four projects. Specifically, the ``Code'' columns for these three project {\em ArgoUML\/}, {\em jFreeChart\/}, and {\em Tuxguitar} have the worst results for all these five methods, and ``Context '' column for {\em jEdit} project have almost all the worst for these five methods. In addition, we compare the results of these prediction among five machine learning methods and again come to the same conclusion that with all attribute set, {\em SVM\/} has the best ability for attribute set prediction. Thus, we recommend to retain all the attribute sets in this prediction, and prefer {\em SVM\/} method over other methods.


%\begin{sidewaystable} [htbp]
%\bicaption[creatingsetfree]{}{克隆创建实例的属性组克隆一致性维护自由预测效果}{Table$\!$}
%{The Effectiveness of Attribute Set on Creating Instances for Consistency-Requirement Free}
%\vspace{0.5em}
%\centering
%\wuhao
%\begin{tabular}{cccccccccccccc}
%\toprule[1.5pt]
%\multirow{2}{*}{\textbf{Metric}}&\multirow{2}{*}{\textbf{Method}}&\multicolumn{3}{c}{\textbf{ArgoUML}}&\multicolumn{3}{c}{\textbf{jEdit}}&\multicolumn{3}{c}{\textbf{jFreeChart}}&\multicolumn{3}{c}{\textbf{Tuxguitar}}\\
%\cline{3-14}
%&&\textbf{All}&\textbf{Code}&\textbf{Context}&\textbf{All}&\textbf{Code}&\textbf{Context}&\textbf{All}&\textbf{Code}&\textbf{Context}&\textbf{All}&\textbf{Code}&\textbf{Context}~\\
%\midrule[1pt]
%\multirow{5}{*}{Percision}
%&BayesNet&0.945&	0.932	&0.929&		0.943&	0.942	&0.9	&	&0.879	&0.789	&0.898		&0.861	&0.848	0.88\\
%&Native&0.917	&0.907&	0.913	&	0.941	&0.932&	0.906	&	0.863&	0.744&	0.873	&	0.853&	0.809	&0.89\\
%&SVM&0.955&	0.937	&0.945	&	0.919	&0.919&	0.928&		0.889	&0.779&	0.889	&	0.872	&0.843	&0.877\\
%&KNN&0.96	&0.94	&0.947	&	0.933&	0.934	&0.926	&	0.905&	0.787&	0.896	&	0.891&	0.856&	0.9\\
%&Tree&0.953&	0.936	&0.943	&	0.936&	0.923	&0.921&		0.891&	0.778&	0.884	&	0.913	&0.842&	0.907\\
%
%\hline
%\multirow{5}{*}{Recall}
%&BayesNet&0.974	&0.958	&0.969	&	0.916	&0.907&	0.936		&0.932	&0.916	&0.944	&	0.917	&0.905	&0.906\\
%&Native&0.94	&0.924	&0.933&		0.85	&0.879&	0.896		&0.927&	0.892	&0.922	&	0.858	&0.86&	0.845\\
%&SVM&0.992	&0.973&	0.983		&0.998	&0.998&	0.984		&0.959	&0.944	&0.959		&0.979	&0.947	&0.957\\
%&KNN&0.962&	0.946&	0.969	&	0.943	&0.968&	0.945		&0.93&	0.919&	0.937	&	0.896	&0.881&	0.907\\
%&Tree&0.969&	0.941	&0.969	&	0.959&	0.963	&0.957	&	0.934	&0.92&	0.939	&	0.935	&0.897	&0.93\\
%\hline
%\multirow{5}{*}{F-Measure}
%&BayesNet&0.959&	0.945&	0.949	&	0.929	&0.924&	0.918	&	0.905&	0.848	&0.921	&	0.888&	0.875&	0.893\\
%&Native&0.928&	0.915	&0.923	&0.893	&0.904	&0.901		&0.894&	0.811&	0.897	&	0.856	&0.834	&0.867\\
%&SVM&0.973&	0.955&	0.964	&	0.957&	0.957&	0.955	&	0.923&	0.854	&0.923&		0.923&	0.892&	0.915\\
%&KNN&0.961&	0.943&	0.958	&	0.938	&0.951&	0.935		&0.917	&0.848	&0.916&		0.893&	0.868	&0.903\\
%&Tree&0.961&	0.938&	0.956	&	0.947	&0.942&	0.939	&	0.912&	0.843	&0.911&		0.924	&0.868&	0.918\\
%\bottomrule[1.5pt]
%\end{tabular}
%\end{sidewaystable}

%\begin{sidewaystable} [htbp]
%\footnotesize
%\bicaption[sdfj1]{}{克隆创建实例的属性组克隆一致性维护自由预测效果}{Table$\!$}
%{The Effectiveness of Attribute Set for Creating Instances for Meeting Consistency-Requirement}
%\vspace{0.5em}
%\centering
%%\wuhao
%\begin{tabular}{cccccccccccccc}
%\toprule[1.5pt]
%\multirow{2}{*}{\textbf{Metric}}&\multirow{2}{*}{\textbf{Method}}&\multicolumn{3}{c}{\textbf{ArgoUML}}&\multicolumn{3}{c}{\textbf{jEdit}}&\multicolumn{3}{c}{\textbf{jFreeChart}}&\multicolumn{3}{c}{\textbf{Tuxguitar}}\\
%\cline{3-14}
%&&\textbf{All}&\textbf{Code}&\textbf{Context}&\textbf{All}&\textbf{Code}&\textbf{Context}&\textbf{All}&\textbf{Code}&\textbf{Context}&\textbf{All}&\textbf{Code}&\textbf{Context}~\\
%\midrule[1pt]
%\multirow{5}{*}{Precision}
%&BayesNet&	0.902	&0.844	&0.878	&	0.472	&0.447	&0.294	&	0.889	&0.836	&0.91	&	0.758	&0.719	&0.752\\
%&Native&	0.78&	0.728&	0.756	&	0.339	&0.352	&0.266	&	0.878	&0.772	&0.873	&	0.646	&0.593	&0.662\\
%&SVM&	0.969	&0.896	&0.934	&	0.96	&0.96&	0.769	&	0.931	&0.879	&0.931	&	0.927&	0.813	&0.863\\
%&KNN&	0.872	&0.815	&0.888		&0.522	&0.66	&0.5		&0.892	&0.839	&0.9	&	0.74&	0.684	&0.767\\
%&Tree&	0.891	&0.799&	0.885	&	0.61	&0.571	&0.529	&	0.894	&0.837&	0.901	&	0.83	&0.697	&0.817\\
%\hline
%\multirow{5}{*}{Recall}
%&BayesNet&	0.808	&0.765&	0.752		&0.575	&0.575	&0.205	&	0.809&	0.636&	0.841	&	0.637&	0.6	&0.697\\
%&Native&	0.714&	0.68	&0.701	&	0.589	&0.507&	0.288		&0.78	&0.542	&0.8	&	0.637	&0.501	&0.743\\
%&SVM&	0.845&	0.779	&0.808	&	0.329	&0.329&	0.411	&	0.823	&0.601&	0.821	&	0.646	&0.567	&0.671\\
%&KNN&	0.864&	0.798	&0.816	&	0.479	&0.479&	0.425	&	0.854&	0.63&	0.838		&0.731	&0.634&	0.751\\
%&Tree&	0.841&	0.782	&0.803	&	0.493	&0.384&	0.37	&	0.831&	0.61&	0.817	&	0.782	&0.586	&0.765\\
%\hline
%\multirow{5}{*}{F-Measure}
%&BayesNet&	0.853&	0.803&	0.81	&	0.519	&0.503&	0.242	&	0.847&	0.722&	0.874	&	0.692&	0.654&	0.724\\
%&Native&	0.746&	0.703	&0.728		&0.43	&0.416	&0.276	&	0.826	&0.637	&0.835		&0.641	&0.543	&0.7\\
%&SVM&	0.902&	0.834&	0.866&		0.49&	0.49	&0.536	&	0.873&	0.714	&0.873	&	0.762	&0.668&	0.755\\
%&KNN&	0.868&	0.806&	0.85	&	0.5&	0.556	&0.459		&0.873	&0.72	&0.868		&0.736&	0.658	&0.759\\
%&Tree&	0.865&	0.79&	0.842	&	0.545&	0.459&	0.435	&	0.861	&0.706&	0.857	&	0.805	&0.637&	0.79\\
%\bottomrule[1.5pt]
%\end{tabular}
%\end{sidewaystable}


根据表~\ref{creatingallavg}~和~\ref{creatingsetavg}~中的实验结果，可以给出对子问题RQ1的回答和建议。在克隆代码创建时，五种机器学习方法都可以应用于克隆代码的一致性维护需求预测中，并具有相似的预测能力。另外，其预测能力仍然具有一点差异，SVM似乎拥有相对最佳的预测效果，因此优先推荐使用SVM技术应用在一致性预测中。与此同时，所使用的属性组在预测中起到了积极的作用，建议程序开发人员在预测时保留所有的属性组进行变化时一致性预测。

%Recommendation: 
%%According to Table~\ref{creatingall}~and Table~\ref{creatingset}, we can give our recommendation for SQ1. At the creating time, the five employed machine learning method can be applied to thus creating consistency prediction with quite similar prediction results. What's more, there still have a little difference among them, the {\em SVM\/} have the nicer ability, recommending that {\em SVM\/} technique should be the first choice. At the same time, our experiment of attribute set show that the selected attribute have the positive impact on this prediction, that recommending that developers should employed them all for their prediction.

\BiSubsection{克隆创建时一致性预测}
{Experiments for Clone Consistency-Requirement}

在本节中解决本章提出的第二个研究问题。
子问题2：
在克隆更改时间，其他机器学习方法是否可以用于克隆一致性要求预测？
属性集是否对我们的预测产生积极或消极的影响？


为了解决这个问题，使用五种不同的机器学习方法在克隆代码变化时进行一致性维护预测，实验结果如表~\ref{changingallavg}~和表~\ref{changingsetavg}~所示。


%
%\begin{table}[htbp]
%\bicaption[changingallfree]{}{克隆变化实例的一致性维护自由预测结果}
%{Table$\!$}{The Effectiveness of Changing Instances for Consistency-Requirement Free}
%\vspace{0.5em}
%\centering
%\wuhao
%\begin{tabular}{cccccc}
%\toprule[1.5pt]
%{\textbf{Project}}&{\textbf{Metric}}&{\textbf{ArgoUML}}&{\textbf{jEdit}}&{\textbf{jFreeChart}}&{\textbf{Tuxguitar}}\\
%\midrule[1pt]
%\multirow{5}{*}{Precision}
%&{BayesNet}&0.774	&0.679	&0.783	&0.508\\
%&{Native}&0.813	&0.723	&0.743	&0.488\\
%&{SVM}&0.761	&0.707&	0.804&	0.483\\
%&{KNN}&0.806&	0.592	&0.726&	0.39\\
%&{Tree}&0.703	&0.59	&0.742&	0.302\\
%\hline
%\multirow{5}{*}{Recall}			
%&{BayesNet}&0.858	&0.679&	0.719&	0.33\\
%&{Native}&0.771	&0.603	&0.748	&0.44\\
%&{SVM}&0.92&	0.679&	0.688	&0.473\\
%&{KNN}&0.792&	0.577	&0.757	&0.253\\
%&{Tree}&0.955&	0.462	&0.624	&0.209\\
%\hline
%\multirow{5}{*}{F-Measure}
%&{BayesNet}&0.814	&0.679	&0.75	&0.4\\
%&{Native}&0.791	&0.657&	0.745&	0.462\\
%&{SVM}&0.833	&0.693	&0.741	&0.478\\
%&{KNN}&0.799&	0.584	&0.741	&0.307\\
%&{Tree}&0.81	&0.518	&0.678&	0.247\\
%\bottomrule[1.5pt]
%\end{tabular}
%\end{table}
%
%\begin{table}[htbp]
%\bicaption[changingallmeeting]{}{克隆变化实例的一致性维护需求预测结果}
%{Table$\!$}{The Effectiveness of Changing Instances for Meeting Consistency-Requirement }
%\vspace{0.5em}
%\centering
%\wuhao
%\begin{tabular}{cccccc}
%\toprule[1.5pt]
%{\textbf{Project}}&{\textbf{Metric}}&{\textbf{ArgoUML}}&{\textbf{jEdit}}&{\textbf{jFreeChart}}&{\textbf{Tuxguitar}}\\
%\midrule[1pt]
%\multirow{5}{*}{Precision}
%&{BayesNet}&0.62	&0.691&	0.797	&0.793\\
%&{Native}&0.571	&0.67	&0.805	&0.813\\
%&{SVM}&0.709&	0.702	&0.784	&0.819\\
%&{KNN}&0.583	&0.602	&0.807	&0.769\\
%&{Tree}&0.639&	0.571&	0.742&	0.753\\
%\hline
%\multirow{5}{*}{Recall}
%&{BayesNet}&0.482&	0.691&	0.847&	0.89\\
%&{Native}&0.633&	0.778&	0.801&	0.84\\
%&{SVM}&0.403&	0.728&	0.871&	0.825\\
%&{KNN}&0.604&	0.617	&0.781&	0.863\\
%&{Tree}&0.165	&0.691&	0.833&	0.833\\
%\hline
%\multirow{5}{*}{F-Measure}
%&{BayesNet}&0.543	&0.691	&0.821	&0.839\\
%&{Native}&0.601&	0.72&	0.803	&0.826\\
%&{SVM}&0.514&	0.715	&0.825&	0.822\\
%&{KNN}&0.594	&0.61	&0.793	&0.814\\
%&{Tree}&0.263&	0.626&	0.785&	0.791\\
%\bottomrule[1.5pt]
%\end{tabular}
%\end{table}


表~\ref{changingallavg}~给出了使用全属性组在五种不同机器学习方法上的克隆变化实例的预测结果。
从这个表可以看出，克隆变化实例在这五种机器学习方法上具有可以接受的预测效果。准确率的范围从58.1\%到79.3 \%，召回率从57.9\%到79.1 \%，而F-measure从57.3 \%到79 \%。
%Table~\ref{changingall} shows the effectiveness of clone-changing consistency prediction. From the table, we observe that the effectiveness of clone-changing prediction is {\em acceptable\/}, having precision values range between 58.1\% and 79.3\%, recall values between 57.9 \% and 79.1\%, and F-measure values between 57.3\% to 79\%.

根据这四个系统的预测结果，通过比较发现预测效果最好的系统是jFreeChart，三个评价指标中拥有最多的最大值，同时jFreeChart中的克隆变化实例的个数也是最多的。然而，系统jEdit是所有系统中预测效果最差的。其原因在于预测模型需要足够的训练集进行训练，然而jEdit中的训练数据太少导致所建立的模型训练不充分，jEdit仅有159个克隆变化实例。%因此可以得出结论，在进行克隆变化的一致性预测是，预测效果将取决于不同项目的训练集规模大小。
本文建议在对克隆代码进行一致性预测时，需要对模型进行充分的训练，以达到最佳的预测效果。

%Comparing the prediction results on these four projects, we observe that the best prediction is project {\em jFreeChart\/}, which has the best results for all three metrics; and the project {\em jEdit\/} yet has the worst prediction in four projects.The reason is that this prediction need more training data to build its predictor well. However, the {\em jEdit\/} subject has the least number data with only 159 counts of clone-changing instances, resulting in worst training for the predictor. \textcolor{red}{the following in blue sounds obvious. need to say it?} \textcolor{blue}{We therefore conclude that the effectiveness for different projects is dependent on the {\em size\/} of the specific project.}

此外，通过对比五种机器学习方法在四个系统上的有效性，除基于决策树的方法外，另外三种方法的预测能力十分相似，没有明显的差异。同时，相对而言SVM方法具有相对较好的预测效果。%具体来说，SVM对{\em jEdit，jFreeChart和Tuxguitar}具有最好的结果，KNN和SVM对于{\em ArgoUML}是最好的。
基于贝叶斯的方法（贝叶斯网络和朴素贝叶斯方法）具有十分友好的预测结果，其预测结果是可以接受的。应该注意的是，{\em KNN}和{\em Decisions Tree}这两种机器学习方法相对而言预测能力不如其他的机器学习方法，尤其是{\em Decisions Tree}方法。

因此，建议开发人员在预测克隆变化实例时也可以考虑SVM，但是贝叶斯的方法也具有不错的预测能力，仅比SVM相差一点点。


%Furthermore, by comparing the effectiveness among the five machine learning methods, we observe that {\em SVM\/} remains the top predictor on these four projects, with most of the best results in precisions, recalls and F-measures. 
%Specifically, SVM have the best results for{\em jEdit, jFreeChart, and Tuxguitar}, and KNN and SVM have the best for {\em ArgoUML}.Meanwhile, both the Bayesian Network and Native Bayes have {\em acceptable\/} predictions. In contrast, the remaining two machine learning methods, {\em KNN\/} and {\em Decisions Tree\/}, do not have sufficiently good results, particularly for {\em Decisions Tree\/}.
%We therefore suggest that the developers should consider {\em SVM\/} as their preference  when performing creating consistency prediction.

\begin{table}[htbp]
\bicaption[changingallavg]{}{克隆变化实例的一致性维护需求平均预测结果}
{Table$\!$}{The average effectiveness of changing instances}
\centering
\wuhao
\begin{tabular}{cccccc}
\toprule[1.5pt]
{指标}&{系统}&{ArgoUML}&{jEdit}&{jFreeChart}&{Tuxguitar}\\
%{\textbf{Project}}&{\textbf{Metric}}&{\textbf{ArgoUML}}&{\textbf{jEdit}}&{\textbf{jFreeChart}}&{\textbf{Tuxguitar}}\\
\midrule[1pt]
\multirow{5}{*}{Precision}
&{BayesNet}&0.724&	0.686&	0.791&0.72\\
&{Native}& 0.734&	0.696	&0.778&	0.729\\
&{SVM}&0.744	&0.704&0.793	&0.733\\
&{KNN}&0.733	&0.597&	0.772&	0.672\\
&{Tree}&0.682	&0.581	&0.742	&0.637\\
\hline
\multirow{5}{*}{Recall}
&{BayesNet}&0.735	&	0.686&0.791&0.746\\
&{Native}&0.726&	0.692&0.778&0.737\\
&{SVM}&0.752	&0.704&0.791&0.734\\
&{KNN}&0.731	&	0.597	&	0.77	&	0.706\\
&{Tree}&0.698&	0.579	&	0.742&0.672\\
\hline
\multirow{5}{*}{F-Measure}
&{BayesNet}&	0.726	&	0.686	&0.79	&0.726\\
&{Native}&0.729&	0.689&0.778&0.733\\
&{SVM}&0.729&0.704	&0.789&	0.733\\
&{KNN}&0.732	&0.597	&0.771	&	0.683\\
&{Tree}&0.632	&	0.573&	0.739&0.651\\
\bottomrule[1.5pt]
\end{tabular}
\end{table}

为探索属性组对预测能力的影响，同样进行在五种不同的机器学习方法上进行了属性组实验，实验结果如表找到属性的贡献，我们还进行属性集的实验，依次删除一个属性集。属性集的有效性如表~\ref{changingsetavg}~所示。依次移除代码属性、上下文属性和演化属性，“All”列是使用全部属性组的实验结果，“Code”、“Cont”、“Evo”分别是是删除{\em Code， Context，Evolution }属性组后的实验结果。
%To explore the contribution for each attribute set, we also construct the attribute set experiment with removing one attribute set in sequence. The effectiveness of attributes set is  shown in Table~\ref{changingset}~. In this table, the ``All'' columns are the results using full attribute sets, and ``Code'', ``Cont'' and ``Evo'' columns are the results for removing {\em Code, Context, Evolution\/} attribute set respectively.


从表中可以看出，三个属性集中任何一个都没有在预测中起到决定性的作用，同时它们任何一个也没有起到消极的作用。尽管如此，三个属性组中的任何一个可能在预测中仅起到了有限的一点积极作用，但三个属性组作为一个整体却仍然可以以可以接受的准确率和召回率有效的预测克隆代码的一致性维护需求。另外，不同的属性集在预测中可能会发挥不同的作用。通过比较五种机器学习方法的预测结果，可以得出与全属性实验相似的结论，即方法之间的差异并不会导致预测结果的明显差异，并取得来的相一致的预测能力。但是，支持向量机似乎拥有相对最佳的预测能力，同样贝叶斯的方法同样也可以取得不错的预测效果。因此在预测中本文需要保留所有属性集，并优先选择SVM方法

%From this table, we can see that each of these three attribute sets may not play a significant impact for thus prediction, and they also do not have the negative impact either. Nonetheless, each of them may have some limited positive impact, yet the whole of them do predict changing instances {\em acceptable\/}. By comparing the results among these five employed machine learning methods, we can get the same conclusions, that the effectiveness showing that the {\em SVM\/} have the nicer ability for this prediction, and {\em KNN\/} and {\em Decision Tree\/} have the worst prediction. Thus, recommended that leave all the attribute sets in this prediction, and prefer {\em SVM\/} technique firstly.

\begin{sidewaystable} [htbp]
\footnotesize
\bicaption[changingsetavg]{}{克隆变化实例的属性组一致性维护需求平均预测效果}
{Table$\!$}{The average effectiveness of attribute set for changing instances}
\vspace{0.5em}
\centering
\begin{tabular}{cccccccccccccccccc}
\toprule[1.5pt]
\multirow{2}{*}{\textbf{Metric}}&\multirow{2}{*}{\textbf{Method}}&\multicolumn{4}{c}{\textbf{ArgoUML}}&\multicolumn{4}{c}{\textbf{jEdit}}&\multicolumn{4}{c}{\textbf{jFreeChart}}&\multicolumn{4}{c}{\textbf{Tuxguitar}}\\
\cline{3-18}
%%&&\textbf{All}&\textbf{Code}&\textbf{Context}&\textbf{Evolution}&\textbf{All}&\textbf{Code}&\textbf{Context}&\textbf{Evolution}&\textbf{All}&\textbf{Code}&\textbf{Context}&\textbf{Evolution}&\textbf{All}&\textbf{Code}&\textbf{Context}&\textbf{Evolution}~\\
&&\textbf{All}&\textbf{Code}&\textbf{Cont}&\textbf{Evo}&\textbf{All}&\textbf{Code}&\textbf{Cont}&\textbf{Evo}&\textbf{All}&\textbf{Code}&\textbf{Cont}&\textbf{Evo}&\textbf{All}&\textbf{Code}&\textbf{Con}&\textbf{Evo}~\\
\midrule[1pt]
\multirow{5}{*}{Percision}
&BayesNet&	0.724&	0.737&	0.712&	0.727&		0.686&	0.698&	0.673&	0.654&	0.791&	0.76&	0.773&	0.76&		0.72&	0.686&	0.672&	0.727\\
&Native&	0.734&	0.743&	0.693&	0.723&		0.696&	0.662&	0.636&	0.676&	0.778&	0.756&	0.731&	0.747&		0.729&	0.7	&0.69&	0.719\\
&SVM&	0.744&	0.737&	0.736&	0.758&		0.704&	0.749&	0.687&	0.642&		0.793&	0.742&	0.769&	0.775&		0.733&	0.678&	0.726&	0.699\\
&KNN&	0.733&	0.692&	0.688&	0.725&		0.597&	0.522&	0.617&	0.68&		0.772&	0.703&	0.744&	0.741&		0.672&	0.639&	0.659&	0.669\\
&Tree&	0.682&	0.689&	0.713&	0.696&		0.581&	0.579&	0.571&	0.595&		0.742&	0.746&	0.711&	0.733&		0.637&	0.621&	0.658&	0.634\\
\hline
\multirow{5}{*}{Recall}
&BayesNet&	0.735&	0.742&	0.724&	0.733&		0.686&	0.698&	0.673&	0.654&	0.791&	0.761&	0.774&	0.761&		0.746&	0.718&	0.709&	0.743\\
&Native&	0.726&	0.738&	0.681&	0.71&		0.692&	0.66&	0.635&	0.673&		0.778&	0.757&	0.732&	0.742&		0.737&	0.703&	0.686&	0.737\\
&SVM&	0.752&	0.742&	0.74&	0.766&		0.704&	0.748&	0.686&	0.642&		0.791&	0.739&	0.768&	0.775&		0.734&	0.678&	0.718&	0.698\\
&KNN&	0.731&	0.698&	0.689&	0.733&		0.597&	0.522&	0.616&	0.679&		0.77&	0.7	&0.742&	0.738&		0.706&	0.681&	0.689&	0.689\\
&Tree&	0.698&	0.7	&0.726&	0.703&		0.579&	0.579&	0.553&	0.591&		0.742&	0.745&	0.711&	0.734&		0.672&	0.653&	0.672&	0.678\\
\hline
\multirow{5}{*}{F-Measure}
&BayesNet&	0.726&	0.739&	0.715&	0.729&		0.686&	0.698&	0.673&	0.654&		0.79&	0.76&	0.772&	0.76&		0.726&	0.695&	0.683&	0.732\\
&Native&	0.729&	0.74&	0.686&	0.714&		0.689&	0.659&	0.634&	0.671&		0.778&	0.756&	0.731&	0.743&		0.733&	0.702&	0.688&	0.725\\
&SVM&	0.729&	0.712&	0.707&	0.75&	0.704&	0.748&	0.684&	0.642&		0.789&	0.733	&0.765&	0.773&		0.733&	0.678&	0.721&	0.698\\
&KNN&	0.732&	0.694&	0.688&	0.727&		0.597&	0.522&	0.616&	0.678&		0.771&	0.701&	0.743&	0.739&		0.683&	0.655&	0.671&	0.677\\
&Tree&	0.632&	0.634&	0.694&	0.635&		0.573&	0.577&	0.533&	0.584&		0.739&	0.741&	0.711&	0.731&		0.651&	0.635&	0.664&	0.651\\
\bottomrule[1.5pt]
\end{tabular}
\end{sidewaystable} 

%\begin{sidewaystable} [htbp]
%\footnotesize
%\bicaption[changingsetfree]{}{克隆变化实例的属性组一致性维护自由预测效果}
%{Table$\!$}{The Effectiveness of Attribute Set for Changing Instances for Consistency-Requirement Free}
%\vspace{0.5em}
%\centering
%%\wuhao
%\begin{tabular}{cccccccccccccccccc}
%\toprule[1.5pt]
%\multirow{2}{*}{\textbf{Metric}}&\multirow{2}{*}{\textbf{Method}}&\multicolumn{4}{c}{\textbf{ArgoUML}}&\multicolumn{4}{c}{\textbf{jEdit}}&\multicolumn{4}{c}{\textbf{jFreeChart}}&\multicolumn{4}{c}{\textbf{Tuxguitar}}\\
%\cline{3-18}
%%%&&\textbf{All}&\textbf{Code}&\textbf{Context}&\textbf{Evolution}&\textbf{All}&\textbf{Code}&\textbf{Context}&\textbf{Evolution}&\textbf{All}&\textbf{Code}&\textbf{Context}&\textbf{Evolution}&\textbf{All}&\textbf{Code}&\textbf{Context}&\textbf{Evolution}~\\
%&&\textbf{All}&\textbf{Code}&\textbf{Cont}&\textbf{Evo}&\textbf{All}&\textbf{Code}&\textbf{Cont}&\textbf{Evo}&\textbf{All}&\textbf{Code}&\textbf{Cont}&\textbf{Evo}&\textbf{All}&\textbf{Code}&\textbf{Con}&\textbf{Evo}~\\
%\midrule[1pt]
%\multirow{5}{*}{Precision}
%&BayesNet&0.774&	0.795	&0.769	&0.788		&0.679	&0.703	&0.667	&0.653		&0.783	&0.731	&0.764	&0.739	&	0.508	&0.424	&0.393	&0.5\\
%&Native&0.813	&0.817	&0.781&	0.808	&	0.723	&0.676	&0.643	&0.697	&	0.743	&0.726&	0.698&	0.685	&	0.488	&0.42	&0.394	&0.486\\
%&SVM&	0.761	&0.747	&0.744	&0.78	&	0.707	&0.732	&0.7	&0.633		&0.804	&0.759	&0.775	&0.77	&	0.483&	0.374	&0.455	&0.413\\
%&KNN&	0.806	&0.766	&0.768	&0.782	&	0.592	&0.513	&0.602	&0.69		&0.726	&0.644	&0.697	&0.688		&0.39	&0.31	&0.354	&0.37\\
%&Tree&	0.703&	0.704	&0.738	&0.705	&	0.59	&0.58&	0.531	&0.61		&0.742	&0.749	&0.666	&0.724		&0.302	&0.265	&0.342	&0.298\\
%\hline
%\multirow{5}{*}{Recall}
%&BayesNet&0.858&	0.833	&0.844	&0.826	&	0.679&	0.667	&0.667	&0.628	&	0.719	&0.71	&0.695	&0.695&		0.33	&0.275	&0.242&	0.396\\
%&Native&0.771	&0.788	&0.733	&0.747	&	0.603&	0.59&	0.577	&0.59	&	0.748	&0.708	&0.675	&0.752	&	0.44	&0.407	&0.407&	0.374\\
%&SVM&	0.92	&0.934&	0.938&	0.91	&	0.679	&0.769	&0.628	&0.641&		0.688&	0.586	&0.657	&0.688	&	0.473	&0.374	&0.495	&0.418\\
%&KNN&	0.792	&0.795	&0.771	&0.837		&0.577	&0.526	&0.641	&0.628		&0.757	&0.692	&0.721	&0.73	&	0.253	&0.198	&0.253	&0.297\\
%&Tree&	0.955	&0.958	&0.92&	0.962		&0.462	&0.513	&0.769&	0.462&		0.624&	0.622&	0.67&	0.626&		0.209&	0.198&	0.297&	0.187\\
%\hline
%\multirow{5}{*}{F-Measure}
%&BayesNet&0.814&	0.814	&0.805&	0.807	&	0.679&	0.684	&0.667	&0.641	&	0.75	&0.721&	0.728	&0.716	&	0.4	&0.333&	0.299	&0.442\\
%&Native&0.791&	0.802&	0.756&	0.776		&0.657	&0.63&	0.608	&0.639	&	0.745	&0.717	&0.686	&0.717	&	0.462&	0.413	&0.4	&0.422\\
%&SVM&	0.833	&0.83&	0.829&	0.84&		0.693&	0.75&	0.662&	0.637&		0.741&	0.662&	0.711&	0.727&		0.478&	0.374&	0.474	&0.415\\
%&KNN&	0.799	&0.78	&0.769&	0.809&		0.584	&0.519	&0.621	&0.658	&	0.741	&0.667	&0.709	&0.708	&	0.307	&0.242	&0.295	&0.329\\
%&Tree&	0.81	&0.812	&0.819&	0.814&		0.518&	0.544&	0.628&	0.526&		0.678&	0.68&	0.668	&0.671&		0.247&	0.226&	0.318&	0.23\\
%\bottomrule[1.5pt]
%\end{tabular}
%\end{sidewaystable}
%
%\begin{sidewaystable} [htbp]
%\footnotesize
%\bicaption[changingsetmeeting]{}{克隆变化实例的属性组一致性维护需求预测效果}
%{Table$\!$}{The Effectiveness of Attribute Set for Changing Instances for Meeting Consistency-Requirement}
%\vspace{0.5em}
%\centering
%%\wuhao
%\begin{tabular}{cccccccccccccccccc}
%\toprule[1.5pt]
%\multirow{2}{*}{\textbf{Metric}}&\multirow{2}{*}{\textbf{Method}}&\multicolumn{4}{c}{\textbf{ArgoUML}}&\multicolumn{4}{c}{\textbf{jEdit}}&\multicolumn{4}{c}{\textbf{jFreeChart}}&\multicolumn{4}{c}{\textbf{Tuxguitar}}\\
%\cline{3-18}
%%%&&\textbf{All}&\textbf{Code}&\textbf{Context}&\textbf{Evolution}&\textbf{All}&\textbf{Code}&\textbf{Context}&\textbf{Evolution}&\textbf{All}&\textbf{Code}&\textbf{Context}&\textbf{Evolution}&\textbf{All}&\textbf{Code}&\textbf{Context}&\textbf{Evolution}~\\
%&&\textbf{All}&\textbf{Code}&\textbf{Cont}&\textbf{Evo}&\textbf{All}&\textbf{Code}&\textbf{Cont}&\textbf{Evo}&\textbf{All}&\textbf{Code}&\textbf{Cont}&\textbf{Evo}&\textbf{All}&\textbf{Code}&\textbf{Con}&\textbf{Evo}~\\
%\midrule[1pt]
%\multirow{5}{*}{Precision}
%&BayesNet&0.62	&0.616&	0.595&	0.6&		0.691&	0.694	&0.679	&0.655	&	0.797	&0.782	&0.781	&0.776		&0.793	&0.776	&0.768&	0.805\\
%&Native&0.571	&0.591&	0.51&	0.547	&	0.67&	0.648	&0.629	&0.656	&	0.805	&0.78	&0.756	&0.794	&	0.813	&0.797	&0.792&	0.799\\
%&SVM&	0.709	&0.716	&0.719	&0.714		&0.702	&0.766	&0.674	&0.65		&0.784	&0.729	&0.764	&0.778	&	0.819	&0.783	&0.82&	0.798\\
%&KNN&	0.583	&0.539	&0.522	&0.605		&0.602	&0.532	&0.632	&0.67		&0.807	&0.749	&0.78	&0.782		&0.769	&0.753	&0.765	&0.772\\
%&Tree&	0.639	&0.657	&0.662	&0.676		&0.571	&0.578	&0.609	&0.58		&0.742	&0.743	&0.745&	0.74		&0.753	&0.745	&0.767	&0.751\\
%\hline
%\multirow{5}{*}{Recall}
%&BayesNet&0.482	&0.554	&0.475	&0.54		&0.691	&0.728	&0.679	&0.679		&0.847	&0.799	&0.835	&0.811		&0.89	&0.871	&0.871	&0.863\\
%&Native&0.633	&0.633	&0.576	&0.633		&0.778	&0.728	&0.691	&0.753		&0.801	&0.794	&0.776	&0.735		&0.84	&0.806	&0.783	&0.863\\
%&SVM&	0.403	&0.345	&0.331	&0.468		&0.728	&0.728	&0.741	&0.642		&0.871	&0.857	&0.854	&0.842		&0.825	&0.783	&0.795	&0.795\\
%&KNN&	0.604	&0.496	&0.518	&0.518		&0.617	&0.519	&0.593	&0.728		&0.781	&0.706	&0.759	&0.745		&0.863	&0.848	&0.84	&0.825\\
%&Tree&	0.165	&0.165	&0.324	&0.165		&0.691	&0.642	&0.346	&0.716		&0.833	&0.84	&0.741	&0.816		&0.833	&0.81	&0.802	&0.848\\
%\hline
%\multirow{5}{*}{F-Measure}
%&BayesNet&0.543	&0.583	&0.528	&0.568		&0.691	&0.711	&0.679	&0.667		&0.821	&0.791	&0.807	&0.793		&0.839	&0.821	&0.816	&0.833\\
%&Native&0.601	&0.611	&0.541	&0.587		&0.72	&0.686	&0.659	&0.701		&0.803	&0.787	&0.766	&0.763		&0.826	&0.802	&0.788	&0.83\\
%&SVM&	0.514	&0.466	&0.453	&0.565		&0.715	&0.747	&0.706	&0.646		&0.825	&0.788	&0.806	&0.809		&0.822	&0.783	&0.807	&0.796\\
%&KNN&	0.594	&0.517	&0.52	&0.558		&0.61	&0.525	&0.611	&0.698		&0.793	&0.727	&0.769	&0.763		&0.814	&0.798	&0.801	&0.798\\
%&Tree&	0.263	&0.264	&0.435	&0.266		&0.626	&0.608	&0.441	&0.641		&0.785	&0.789	&0.743	&0.776		&0.791	&0.776	&0.784	&0.796\\
%\bottomrule[1.5pt]
%\end{tabular}
%\end{sidewaystable} 


根据对克隆变化实例的预测结果（表~\ref{changingallavg}~和~\ref{changingsetavg}~），可以对RQ2进行回答。当克隆代码发生变化时，五种机器学习方法在现有的属性值上都具有可以接受的预测能力，合理的准确率、召回率和F值。尽管SVM方法具有相对较好的预测效果，但是彼此之间的相差并不大。同时，所提起的属性组作为一个整体在预测中起到了积极的作用。所有属于整体的属性都对这一预测产生了积极的影响。因此建议开发人员在预测时使用全部的属性组，并使用SVM作为预测模型。


%Recommendation: 
%According to this results of changing prediction with Table~\ref{changingall}~and~\ref{changingset}, we have the answer for SQ2. At the changing time, our five employed machine learning methods have the {\em acceptable\/} results of this changing consistency prediction. Although most all their prediction ability are similar, the {\em SVM\/} still have the nicer prediction. And, all the attribute set as a whole have their positive impact in this prediction. We therefore suggest that the developer keep all the attributes in their prediction, and consider that employ {\em SVM\/} as the classification model when the need to predict changing instances.


\BiSubsection{软件开发过程中的克隆代码一致性预测}
{Predicting Clone Consistency during Development Time}

在这个讨论中，我们比较克隆和变化预测来解决最后一个研究问题。
子问题3：
他们应该采用哪种机器学习技术作为他们的偏好？而且，开发人员如何执行这些克隆预测来实现实践中的最佳效果？

%{\bf RQ3:}Which technique of machine learning should they employ as their preference? And, how the developers perform these clone predictions to achieve the preferably effectiveness in practice? 

根本节将据上面两节的实验结果，并结合软件开发过程，帮助程序开发人员在实践中运用克隆代码一致性维护需求预测，从而回答本章提出的上面第三个研究问题。

从机器学习方法的角度上来看，本文使用机器学习方法均取得了不错的预测能力，预测结果具有很大的相似性，表明本文所选择的属性可以很好的表示克隆代码创建实例和变化实例，并不依赖于某个具体的机器学习方法。因此，程序开发人员可以根据自己的喜好或者情况选择合适的机器学习方法。当程序开发人员无法决策使用何种机器学习方法，本文强烈建议使用SVM机器学习方法。因为上面的两个小节的实验结果表明，SVM在克隆创建时和变化时均取得了相对较好的预测能力。除此之外，本文还建议开发人员在克隆创建的时候选择使用于KNN和Tree模型，以及在克隆变化时使用BayesNet和Native Bayes方法，从而可以保证这些方法具有相同或更好的预测能力。对于属性集的选择，本文还建议开发人员应该选择并使用本文所提取的全部属性集，因为这些属性值在预测中起到了积极的作用。除此之外，本文还建议如果开发者能够保证获得有效的结果，开发人员可以探索更多属性和机器学习方法构建自己的预测。

%According to the last two experiments, we can provide our recommendations to help developers in conducting clone consistency maintenance.  From the prespective of selecting right predictive tool, we strongly recommend using {\em SVM\/} machine learning method because of its {\em respectably\/} effectiveness prediction results for these four experimental projects both at creating and changing time. In addition, we also suggest that developer choose the {\em KNN\/} and {\em Tree\/} model for creating instances, and {\em BayesNet and Native Bayes\/} for changing instance when they can guarantee these methods have the same or better prediction ability. From the perspective of selecting attribute sets to enable prediction, we recommend that developers should select {\em all\/} the attribute sets to perform their prediction as these attribute sets demonstrate their positive contribution in prediction.

通过对比克隆创建实例和克隆变化时的预测结果（表~\ref{creatingallavg}~和~表\ref{changingallavg}），发现预测效果的好坏会依赖于具体的系统。具体来说，克隆创建实例的预测效果要好于克隆变化实例的预测效果，而在这两个预测中，系统jEdit就几乎都具有最差的预测结果。原因在于jEdit的克隆实例的规模太小，不能对其自身的预测模型进行较好的训练，从而导致预测效果最差。因此，本文建议开发人员在进行克隆创建和变化实例时，需要在软件演化一定版本后收集到足够的训练数据后再进行训练和预测。在软件开发初始阶段，由于系统中缺少训练数据，可以使用跨项目预测的方法解决该问题，但需要对跨项目预测做进一步的研究，从而达到较好的预测效果。

%%Comparing Tables~\ref{creatingall}~and~\ref{changingall}, we can find that these two predictions have different effectiveness, which are impacted by the specific project's {\em size\/}. Specifically, the effectiveness for clone creating prediction is better than changing prediction, and  in changing prediction project {\em jEdit\/} has almost worst results.We believe that prediction effectiveness is dependent of the {\em scale\/} of the data set from its software's repository, meaning that this clone consistency prediction model needs more training data, specially for clone changing prediction. We therefore recommend that the developer should perform clone consistency prediction when they collect enough clone instances after versions are evolved. 
%Supposing that there do not have these, the other technique from the defect prediction may enter the developers' mind that using the cross-project prediction.
%However, the more observation on this cross-project are need before its performing.

为了结合软件开发过程，本文还从软件开发的不同角度给出相关的建议，让开发人员在实践中应用克隆代码一致性维护需求时实现最佳的预测效果。
%From software development perspective, we recommend that developers aim to achieve preferably effectiveness in practice. 

在软件开发的初始阶段，主要任务是快速的进行软件开发，并同时向系统中添加新的功能。这种特点可能会促使程序开发人员大量的进行复制粘贴操作，复用既有的代码进行快速开发。因此，本文建议开发人员在软件开发的初始阶段使用克隆代码创建时的一致性维护预测方法。进一步地，由于要向软件中引入新的功能，因此，建议使用该模型预测克隆代码的一致性维护自由的克隆，仅仅避免那些可能会引发一致性变化的克隆代码，进而快速的开发软件。但是，由于在最初始的阶段，软件系统可能仅仅具有几个版本，因此系统中的克隆创建实例不够多，导致预测数据不足的数据不足，无法完全的训练预测模型。为了解决这个问题，可以使用跨项目预测方法用于克隆代码创建时的预测，见本文第三章中的跨项目预测部分。

%At the start stage of development, the main task is that developing the software fatly and adding the new function to the software, that may lead to perform creating operation frequently. We therefore recommend developers employ this approach to predict creating consistency. However, if the software may evolve only small versions, this can lead to insufficient data and thus affects its predictive well. In this situation, the cross-project prediction can be construct for code creating prediction, which is utilized in work \cite{wang2014predicting}.

在开发的中间阶段，主要任务是添加新功能并修复包括克隆一致性缺陷在内的暴露缺陷。因此，我们建议开发人员应该同时考虑两者来预测克隆创建实例和克隆变化实例。在大多数开发任务的软件演进之后，可能有足够的克隆克隆实例的培训数据和用于更改实例的训练数据不足。这些足够的数据可以训练克隆预测器，以帮助开发人员关心克隆一致性。对于变化的预测，开发人员应该在work \cite{zhang2016predicting}中描述的跨项目预测中建立和训练模型。

%At the middle stage of development, the main task is that adding the new function and fixing the expose defects including the clone consistency defects. Therefore, we recommend that the developer should consider performing both the predictions for clone-creating instance and clone-changing instances. After these evolutions of software with more task completed during development, there may have sufficient training data for clone creating instance and insufficient training data for clone-changing instances. The issue with insufficient data is that our system {\em cannot\/} train the clone-creating predictor sufficiently well, that troubling developer for these creating consistency.For thus this situation of changing prediction, the developer should build and train the model with cross-project prediction described in previous work \cite{zhang2016predicting}

在开发的最后阶段，主要任务是维护可能导致大量克隆更改一致性的软件。因此，我们建议开发人员对克隆更改实例执行克隆一致性预测。
由于软件的不断发展，其项目克隆更改实例的数据将足以对预测器进行良好的训练。
%At the last stage of development, the main task is to maintain the software so that there may be plenty of clone changes consistency instances. At that stage, we thus recommend developers to perform the clone consistency prediction for clone-changing instances. In the case that software undergoing many generations of evolution, the data for clone changing instance of this project itself will have sufficient data for training the predictor well.However, our approach can only help predict the need for change consistency-requirement, {\em not} to help developers to maintain the clone change consistency.

但是，这种方法只能预测变化的一致性要求，不能帮助开发人员维护克隆更改的一致性。为了实现克隆一致性的目标，我们还建议开发人员采取措施，通过一致性维护和管理技术（如\cite{cheng2016rule}和\cite{nguyen2012clone}）执行克隆一致的更改。

%Finally, To accomplish the objective of ensuring clone consistency, we recommend that developers should take in other measures to perform such clone consistent changes, employ the techniques of consistency maintenance and management, such as \cite{cheng2016rule} and \cite{nguyen2012clone}.



%%\section{Threats to Validity}

%Our empirical study work may subject to some threats of validities including construct validity and conclusion validity.

%One concern is about threat to construct validity, related to the ``creating and changing'' metrics we used in the construction and evaluation.We provide two kind ``consistent change'' patterns for clone groups, specifically type-1 consistent change pattern for creating and type-2 for changing.Both of them might not be truly accurate for clone groups that include {\em more than two\/} clone fragments, as clones in a clone group may not really match the pattern condition. Nonetheless, this will not be really significant because of two reasons: (1) Most of the clone groups found in the repositories are of size 2; (2)We believe that, when consistent change happened to at least two clone fragments in a group type-1 consistent change for creating indeed increase clone maintenance cost, as well as that when changes happening to clones causing type-2 consistent change in a clone group developers also indeed should check through all clones in such changing group for consistency to avoid consistency-defect.

%On the other hand, threats to validity of conclusion concerns about the population of clone instances in software's repository as well as the employed machine learning methods. Software's repository supplies our clone instances to machine learning methods, that require adequate training data to train the prediction model well; therefore, software's repository should ideally contain several revisions or have enough amount of clone instances. Consequently, our approach maybe not applicable for a new repository or the repository without enough instances. In thus situation, we recommend developers to be careful in introducing code clones by copy-and-paste operation to avoid the code clones; and recommend developer take other measures to maintain the clones and their changes, such as effective clone management tools. 

%In this work, we do not improve the machine learning technique. For these learning methods, there still have some space for enhancing the predictive ability through adjusting specific parameters. Our defense to this argument is that the effectiveness of prediction is already reasonable for clone consistency prediction. Obtaining the best configuration of these methods for the best prediction effectiveness will be anther task that is beyond the existing scope of this  research.



\BiSection{结论}
{Summary of this Chapter}

在软件开发过程中，克隆创建实例（复制粘贴操作）和克隆变化实例（克隆修改操作）可能会导致克隆代码在演化过程中的一致性变化，从而可能增加软件维护的代价。因此，本章统一了克隆创建和变化时的一致性维护需求定义，并结合软件开发过程对克隆代码一致性维护需求预测进行了实证研究。为帮助程序开发人员在实际应用中预测克隆代码的一致性维护，本章结合软件开发过程提出了一个研究问题，并使用五种不同的机器学习方法预测克隆代码的一致性维护需求；同时设计和开发了了一个克隆代码一致性预测插件，可以帮助程序开发人员在实际的开发过程中预测克隆代码的一致性，切实的提高软件的可维护性和软件质量。 %对于每个克隆实例，我们提取不同的属性集以表示克隆创建和更改实例。具体来说，对于创建实例，我们提取了用于粘贴代码的复制代码和上下文属性的代码属性的两个变体属性集，并引入了一组{\ em演化属性}来捕获创建实例的演化历史的特征。因此，我们的属性{\ em从个人，环境和进化的角度提供关于代码更改的整体视图}。我们使用这些数据为使用WEKA实现的每个存储库构建一个贝叶斯网络
在四个开源系统上分别在克隆代码创建时和变化时进行了实验分组，从三个不同的角度回答了本文所提出的研究问题。实验结果表明使用不同的机器学习方法所构建的预测模型在克隆一致性维护需求问题上具有相一致的预测效果，可以以高效地预测克隆创建实例一致性且有效地预测克隆变化的一致性问题。尽管如此，本文建议开发人员采用SVM方法进行预测，因为SVM在两种时刻均具最佳的预测能力。同时，为帮助软件开发人员在实际中对克隆一致性进行预测，本文结合软件开发过程在不同的软件开发阶段给出了不同的克隆一致性预测的建议。最后，本文结合实际的软件开发过程，基于eclipse实现了一个克隆代码一致性维护插件，可以在软件开发过程中帮助程序开发人员预测一致性，帮助降低软件维护代价，提高可维护性。

%The behaviors of creating and changing clones by developers -- in software development -- will increase to the burden of software maintenance cost, as there is increased needs for potential maintenance of consistent change in a clone group.   In this paper, we raise a research problem for clone consistency-requirement prediction based on previous work of \cite{wang2014predicting}\cite{zhang2016predicting}, and construct an empirical study addressing this problem with {\em five\/} different machine learning methods through unifying clone consistency perdition both at creating and changing times. We adapt these definitions of clone consistency to this unified creating and changing predictions with their extracted attribute sets. %For each clone instance, we extract the diverse attribute set to represent clone creating and changing instance. Specifically, for creating instance we extract two variant attribute sets of code attributes for copied code and context attributes for pasted code, and introduce a set of {\em evolution attributes} to capture the characteristics of evolution history for creating instance. Consequently, our attributes {\em provide a holistic view about code change, from perspectives of individual, environment, and evolution}.  We use these data to build a Bayesian network for each repository, implemented using WEKA. 
%We conducted experiments on four open source software projects, with the aim to address our proposed problem form different perspectives. The results show that our models employed different machine methods all have similar reasonable ability of consistency prediction, and all having good effectiveness for creating instances and acceptable for changing instances. Meanwhile, we recommend developer employing SVM technique for their predictor due to the latter's good predictive power, both for clone creating and changing. Furthermore, we provide our recommendations for the developer when they perform clone consistency prediction at different software development time in practice.

%为了跟进，我们首先打算建立一个通用的跨项目预测器，以增强没有足够数据的新的软件存储库的能力来训练其模型。通过这个跨项目预测器，开发人员可以忽略开发人员的培训步骤，这可以真正节省克隆一致性预测的时间。此外，我们打算通过为变化预测引入新的属性或属性选择来增强预测变量的能力。
%对于克隆更改实例，我们还打算在开发过程中构建一种新技术来支持克隆一致的更改以保存。此外，我们打算将此模型构建和预测过程集成到IDE中，如Eclipse。c我们认为，这种全面的方法可以大大提升软件可维护性，从而提高软件质量，因为开发人员现在可以更加了解当需要调查克隆组的一致性要求时，避免出现一致性缺陷的潜在风险。

%To follow up, we intend to build a general predictor for cross-project prediction, that will enhance the ability for the new software repository not having enough data to train its own model well. With this cross-project predictor, developers may also ignore the training phase at the developing, that can indeed increase the efficiency of clone consistency prediction. In addition, we also intend to enhance the predictive ability of the predictor for the changing prediction by introducing new attributes or selecting best sub attributes. In addition, we intend to integrate this model construction and prediction processes into an IDE, such as Eclipse.  For the clone changing instance, we also intend to build  a new technique to support the clone consistent change during the development to save the .

%We believe that this holistic approach can be a solid boost to software maintainability to improve software quality, as developers can now be more aware of when consistency-requirement of a clone group need to be investigated, avoiding the potential risk of consistency-defects. 

